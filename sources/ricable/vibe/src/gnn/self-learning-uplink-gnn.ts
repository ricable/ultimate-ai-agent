/**
 * Self-Learning GNN for Ericsson Uplink Optimization
 *
 * This module implements a self-learning Graph Neural Network system for optimizing
 * P-Zero Nominal PUSCH and Alpha parameters in LTE/5G networks. It integrates with
 * ruvector for advanced GNN operations, tensor compression, and differentiable search.
 *
 * Key Features:
 * - RuVector GNN Layer with multi-head attention
 * - Online learning with experience replay
 * - Adaptive tensor compression for model efficiency
 * - Differentiable search for parameter optimization
 * - Continuous adaptation based on network feedback
 *
 * Based on: Ericsson's Digital Twin approach for RAN optimization
 */

import type {
  CellKPISnapshot,
  NeighborRelation,
} from '../models/ran-kpi.js';
import {
  SurrogateGraphBuilder,
  GNNSurrogateModel,
  IssueCellDetector,
  DEFAULT_SURROGATE_CONFIG,
  type SurrogateGraph,
  type PowerControlParams,
  type CellOptimizationResult,
  type SurrogateModelConfig,
} from './network-surrogate-model.js';

// ============================================================================
// RUVECTOR INTEGRATION TYPES
// ============================================================================

/**
 * RuVector compression levels for adaptive tensor management
 */
export type CompressionLevel = 'none' | 'half' | 'pq8' | 'pq4' | 'binary';

/**
 * RuVector GNN layer configuration
 */
export interface RuVectorLayerConfig {
  inputDim: number;
  hiddenDim: number;
  numHeads: number;
  dropout: number;
  useResidual: boolean;
  useLayerNorm: boolean;
}

/**
 * Compressed tensor representation
 */
export interface CompressedTensor {
  data: Float32Array | Int8Array | Uint8Array;
  shape: number[];
  compressionLevel: CompressionLevel;
  accessFrequency: number;
  lastAccessed: Date;
}

/**
 * Experience sample for replay buffer
 */
export interface ExperienceSample {
  id: string;
  timestamp: Date;
  graph: SurrogateGraph;
  cellId: string;
  params: PowerControlParams;
  predictedSINR: number;
  actualSINR: number;
  reward: number;
  priority: number;
}

/**
 * Self-learning model state
 */
export interface SelfLearningState {
  modelVersion: number;
  totalSamples: number;
  totalUpdates: number;
  avgLoss: number;
  avgReward: number;
  learningRate: number;
  explorationRate: number;
  lastCheckpoint: Date | null;
  metrics: LearningMetrics;
}

/**
 * Learning metrics for monitoring
 */
export interface LearningMetrics {
  sinrPredictionError: number;
  optimizationSuccessRate: number;
  avgSINRImprovement: number;
  neighborImpactScore: number;
  convergenceScore: number;
  adaptationRate: number;
}

// ============================================================================
// RUVECTOR GNN LAYER IMPLEMENTATION
// ============================================================================

/**
 * RuVector-style GNN Layer with multi-head attention
 *
 * This layer implements message passing with:
 * - Multi-head self-attention for neighbor aggregation
 * - Adaptive dropout for regularization
 * - Residual connections and layer normalization
 * - Support for tensor compression
 */
export class RuVectorGNNLayer {
  private config: RuVectorLayerConfig;

  // Attention weights (compressed)
  private W_query: CompressedTensor;
  private W_key: CompressedTensor;
  private W_value: CompressedTensor;
  private W_output: CompressedTensor;

  // Layer normalization parameters
  private gamma: Float32Array;
  private beta: Float32Array;

  // Training state
  private dropoutMask: Float32Array | null = null;
  private isTraining: boolean = false;
  private accessCount: number = 0;

  constructor(config: Partial<RuVectorLayerConfig> = {}) {
    this.config = {
      inputDim: config.inputDim ?? 24,
      hiddenDim: config.hiddenDim ?? 64,
      numHeads: config.numHeads ?? 4,
      dropout: config.dropout ?? 0.1,
      useResidual: config.useResidual ?? true,
      useLayerNorm: config.useLayerNorm ?? true,
    };

    // Initialize weights with Xavier initialization
    this.W_query = this.initializeCompressedWeight(
      this.config.inputDim,
      this.config.hiddenDim
    );
    this.W_key = this.initializeCompressedWeight(
      this.config.inputDim,
      this.config.hiddenDim
    );
    this.W_value = this.initializeCompressedWeight(
      this.config.inputDim,
      this.config.hiddenDim
    );
    this.W_output = this.initializeCompressedWeight(
      this.config.hiddenDim,
      this.config.hiddenDim
    );

    // Initialize layer normalization
    this.gamma = new Float32Array(this.config.hiddenDim).fill(1);
    this.beta = new Float32Array(this.config.hiddenDim).fill(0);
  }

  /**
   * Forward pass through the GNN layer
   */
  forward(
    nodeFeatures: number[][],
    adjacencyMatrix: number[][],
    edgeFeatures?: number[][][]
  ): number[][] {
    this.accessCount++;
    this.updateCompressionLevels();

    const numNodes = nodeFeatures.length;
    const { hiddenDim, numHeads } = this.config;
    const headDim = Math.floor(hiddenDim / numHeads);

    // Decompress weights for computation
    const Wq = this.decompressTensor(this.W_query);
    const Wk = this.decompressTensor(this.W_key);
    const Wv = this.decompressTensor(this.W_value);
    const Wo = this.decompressTensor(this.W_output);

    // Compute queries, keys, values
    const queries = this.matmul(nodeFeatures, Wq);
    const keys = this.matmul(nodeFeatures, Wk);
    const values = this.matmul(nodeFeatures, Wv);

    // Multi-head attention
    const attended: number[][] = Array(numNodes)
      .fill(null)
      .map(() => Array(hiddenDim).fill(0));

    for (let h = 0; h < numHeads; h++) {
      const startIdx = h * headDim;
      const endIdx = startIdx + headDim;

      for (let i = 0; i < numNodes; i++) {
        const attentionWeights: number[] = [];
        const neighborIndices: number[] = [];

        // Compute attention scores for neighbors
        for (let j = 0; j < numNodes; j++) {
          if (adjacencyMatrix[i][j] > 0 || i === j) {
            let score = 0;

            // Scaled dot-product attention
            for (let k = startIdx; k < endIdx; k++) {
              score += queries[i][k] * keys[j][k];
            }
            score /= Math.sqrt(headDim);

            // Add edge features bias if available
            if (edgeFeatures && edgeFeatures[i]?.[j]?.length > 0) {
              const edgeBias = edgeFeatures[i][j].reduce((a, b) => a + b, 0) * 0.05;
              score += edgeBias;
            }

            // Weight by adjacency strength
            if (i !== j) {
              score += Math.log(adjacencyMatrix[i][j] + 0.01);
            }

            attentionWeights.push(score);
            neighborIndices.push(j);
          }
        }

        // Softmax normalization
        const maxScore = Math.max(...attentionWeights, -Infinity);
        const expScores = attentionWeights.map(s => Math.exp(s - maxScore));
        const sumExp = expScores.reduce((a, b) => a + b, 1e-9);
        const normalizedWeights = expScores.map(s => s / sumExp);

        // Weighted aggregation of values
        for (let k = startIdx; k < endIdx; k++) {
          let aggregated = 0;
          for (let n = 0; n < neighborIndices.length; n++) {
            aggregated += normalizedWeights[n] * values[neighborIndices[n]][k];
          }
          attended[i][k] = aggregated;
        }
      }
    }

    // Output projection
    let output = this.matmul(attended, Wo);

    // Apply dropout during training
    if (this.isTraining && this.config.dropout > 0) {
      output = this.applyDropout(output);
    }

    // Residual connection
    if (this.config.useResidual) {
      output = this.addResidualConnection(nodeFeatures, output);
    }

    // Layer normalization
    if (this.config.useLayerNorm) {
      output = this.layerNormalize(output);
    }

    return output;
  }

  /**
   * Update weights using gradient descent
   */
  updateWeights(gradients: {
    W_query: number[][];
    W_key: number[][];
    W_value: number[][];
    W_output: number[][];
  }, learningRate: number): void {
    // Update each weight matrix
    this.W_query = this.applyGradient(this.W_query, gradients.W_query, learningRate);
    this.W_key = this.applyGradient(this.W_key, gradients.W_key, learningRate);
    this.W_value = this.applyGradient(this.W_value, gradients.W_value, learningRate);
    this.W_output = this.applyGradient(this.W_output, gradients.W_output, learningRate);
  }

  /**
   * Set training mode
   */
  setTraining(training: boolean): void {
    this.isTraining = training;
    if (!training) {
      this.dropoutMask = null;
    }
  }

  /**
   * Get layer configuration
   */
  getConfig(): RuVectorLayerConfig {
    return { ...this.config };
  }

  /**
   * Export weights for checkpointing
   */
  exportWeights(): {
    W_query: Float32Array;
    W_key: Float32Array;
    W_value: Float32Array;
    W_output: Float32Array;
    gamma: Float32Array;
    beta: Float32Array;
  } {
    return {
      W_query: this.decompressTensor(this.W_query),
      W_key: this.decompressTensor(this.W_key),
      W_value: this.decompressTensor(this.W_value),
      W_output: this.decompressTensor(this.W_output),
      gamma: new Float32Array(this.gamma),
      beta: new Float32Array(this.beta),
    };
  }

  /**
   * Import weights from checkpoint
   */
  importWeights(weights: {
    W_query: Float32Array;
    W_key: Float32Array;
    W_value: Float32Array;
    W_output: Float32Array;
    gamma?: Float32Array;
    beta?: Float32Array;
  }): void {
    const { inputDim, hiddenDim } = this.config;
    this.W_query = this.createCompressedTensor(weights.W_query, [inputDim, hiddenDim]);
    this.W_key = this.createCompressedTensor(weights.W_key, [inputDim, hiddenDim]);
    this.W_value = this.createCompressedTensor(weights.W_value, [inputDim, hiddenDim]);
    this.W_output = this.createCompressedTensor(weights.W_output, [hiddenDim, hiddenDim]);

    if (weights.gamma) this.gamma = weights.gamma;
    if (weights.beta) this.beta = weights.beta;
  }

  // Private helper methods

  private initializeCompressedWeight(fanIn: number, fanOut: number): CompressedTensor {
    const std = Math.sqrt(2 / (fanIn + fanOut));
    const data = new Float32Array(fanIn * fanOut);
    for (let i = 0; i < data.length; i++) {
      data[i] = (Math.random() * 2 - 1) * std;
    }
    return {
      data,
      shape: [fanIn, fanOut],
      compressionLevel: 'none',
      accessFrequency: 1.0,
      lastAccessed: new Date(),
    };
  }

  private createCompressedTensor(data: Float32Array, shape: number[]): CompressedTensor {
    return {
      data,
      shape,
      compressionLevel: 'none',
      accessFrequency: 1.0,
      lastAccessed: new Date(),
    };
  }

  private decompressTensor(tensor: CompressedTensor): Float32Array {
    tensor.lastAccessed = new Date();
    tensor.accessFrequency = Math.min(1.0, tensor.accessFrequency + 0.1);

    if (tensor.compressionLevel === 'none') {
      return tensor.data as Float32Array;
    }

    // For compressed tensors, decompress to Float32Array
    const decompressed = new Float32Array(tensor.shape[0] * tensor.shape[1]);
    const compressed = tensor.data;

    switch (tensor.compressionLevel) {
      case 'half':
        // Half precision: scale back
        for (let i = 0; i < decompressed.length && i < compressed.length; i++) {
          decompressed[i] = (compressed[i] as number) / 32767;
        }
        break;
      case 'pq8':
      case 'pq4':
        // Product quantization: approximate reconstruction
        for (let i = 0; i < decompressed.length && i < compressed.length; i++) {
          decompressed[i] = ((compressed[i] as number) - 128) / 128;
        }
        break;
      case 'binary':
        // Binary: -1 or 1
        for (let i = 0; i < decompressed.length && i < compressed.length; i++) {
          decompressed[i] = (compressed[i] as number) > 0 ? 0.1 : -0.1;
        }
        break;
    }

    return decompressed;
  }

  private updateCompressionLevels(): void {
    // Decay access frequency over time
    const decayFactor = 0.99;
    const tensors = [this.W_query, this.W_key, this.W_value, this.W_output];

    for (const tensor of tensors) {
      tensor.accessFrequency *= decayFactor;

      // Determine compression level based on access frequency
      const freq = tensor.accessFrequency;
      let newLevel: CompressionLevel;

      if (freq > 0.8) {
        newLevel = 'none';
      } else if (freq > 0.4) {
        newLevel = 'half';
      } else if (freq > 0.1) {
        newLevel = 'pq8';
      } else if (freq > 0.01) {
        newLevel = 'pq4';
      } else {
        newLevel = 'binary';
      }

      // Only compress if moving to a more compressed level
      if (newLevel !== tensor.compressionLevel &&
          this.compressionOrder(newLevel) > this.compressionOrder(tensor.compressionLevel)) {
        this.compressTensor(tensor, newLevel);
      }
    }
  }

  private compressionOrder(level: CompressionLevel): number {
    const order = { none: 0, half: 1, pq8: 2, pq4: 3, binary: 4 };
    return order[level];
  }

  private compressTensor(tensor: CompressedTensor, targetLevel: CompressionLevel): void {
    const decompressed = this.decompressTensor(tensor);
    const size = tensor.shape[0] * tensor.shape[1];

    switch (targetLevel) {
      case 'half':
        tensor.data = new Float32Array(size);
        for (let i = 0; i < size; i++) {
          (tensor.data as Float32Array)[i] = Math.round(decompressed[i] * 32767);
        }
        break;
      case 'pq8':
        tensor.data = new Int8Array(size);
        for (let i = 0; i < size; i++) {
          (tensor.data as Int8Array)[i] = Math.round(decompressed[i] * 127);
        }
        break;
      case 'pq4':
        tensor.data = new Int8Array(size);
        for (let i = 0; i < size; i++) {
          (tensor.data as Int8Array)[i] = Math.round(decompressed[i] * 7);
        }
        break;
      case 'binary':
        tensor.data = new Uint8Array(size);
        for (let i = 0; i < size; i++) {
          (tensor.data as Uint8Array)[i] = decompressed[i] > 0 ? 1 : 0;
        }
        break;
    }

    tensor.compressionLevel = targetLevel;
  }

  private applyGradient(
    tensor: CompressedTensor,
    gradient: number[][],
    learningRate: number
  ): CompressedTensor {
    const weights = this.decompressTensor(tensor);
    const [rows, cols] = tensor.shape;

    for (let i = 0; i < rows && i < gradient.length; i++) {
      for (let j = 0; j < cols && j < (gradient[i]?.length ?? 0); j++) {
        weights[i * cols + j] -= learningRate * gradient[i][j];
      }
    }

    return {
      ...tensor,
      data: weights,
      compressionLevel: 'none', // Reset compression after update
      accessFrequency: Math.min(1.0, tensor.accessFrequency + 0.2),
      lastAccessed: new Date(),
    };
  }

  private matmul(a: number[][], b: Float32Array): number[][] {
    const m = a.length;
    const k = a[0]?.length ?? 0;
    const n = b.length / k;
    const result: number[][] = Array(m)
      .fill(null)
      .map(() => Array(n).fill(0));

    for (let i = 0; i < m; i++) {
      for (let j = 0; j < n; j++) {
        for (let l = 0; l < k; l++) {
          result[i][j] += a[i][l] * b[l * n + j];
        }
      }
    }
    return result;
  }

  private applyDropout(matrix: number[][]): number[][] {
    const dropoutRate = this.config.dropout;
    const scale = 1 / (1 - dropoutRate);

    return matrix.map(row =>
      row.map(val => (Math.random() > dropoutRate ? val * scale : 0))
    );
  }

  private addResidualConnection(original: number[][], transformed: number[][]): number[][] {
    const { inputDim, hiddenDim } = this.config;
    return transformed.map((row, i) =>
      row.map((val, j) => {
        const origVal = j < inputDim && i < original.length ? original[i][j] : 0;
        return val + origVal;
      })
    );
  }

  private layerNormalize(matrix: number[][]): number[][] {
    const eps = 1e-6;
    return matrix.map(row => {
      const mean = row.reduce((a, b) => a + b, 0) / row.length;
      const variance = row.reduce((a, b) => a + (b - mean) ** 2, 0) / row.length;
      const std = Math.sqrt(variance + eps);
      return row.map((v, i) => {
        const normalized = (v - mean) / std;
        return this.gamma[i] * normalized + this.beta[i];
      });
    });
  }
}

// ============================================================================
// EXPERIENCE REPLAY BUFFER
// ============================================================================

/**
 * Prioritized Experience Replay Buffer for online learning
 *
 * Features:
 * - Priority-based sampling (higher priority = more likely to be sampled)
 * - Importance sampling weights for unbiased updates
 * - Automatic priority updates based on TD error
 */
export class ExperienceReplayBuffer {
  private buffer: ExperienceSample[] = [];
  private maxSize: number;
  private alpha: number; // Priority exponent
  private beta: number;  // Importance sampling exponent
  private betaIncrement: number;

  constructor(
    maxSize: number = 10000,
    alpha: number = 0.6,
    beta: number = 0.4,
    betaIncrement: number = 0.001
  ) {
    this.maxSize = maxSize;
    this.alpha = alpha;
    this.beta = beta;
    this.betaIncrement = betaIncrement;
  }

  /**
   * Add a new experience sample
   */
  add(sample: Omit<ExperienceSample, 'id' | 'priority'>): void {
    const priority = Math.abs(sample.predictedSINR - sample.actualSINR) + 0.01;

    const fullSample: ExperienceSample = {
      ...sample,
      id: `exp_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
      priority: priority ** this.alpha,
    };

    if (this.buffer.length >= this.maxSize) {
      // Remove lowest priority sample
      const minIdx = this.buffer.reduce(
        (minI, s, i, arr) => (s.priority < arr[minI].priority ? i : minI),
        0
      );
      this.buffer.splice(minIdx, 1);
    }

    this.buffer.push(fullSample);
  }

  /**
   * Sample a batch with priority-based selection
   */
  sample(batchSize: number): {
    samples: ExperienceSample[];
    weights: number[];
    indices: number[];
  } {
    if (this.buffer.length === 0) {
      return { samples: [], weights: [], indices: [] };
    }

    const actualBatchSize = Math.min(batchSize, this.buffer.length);

    // Calculate sampling probabilities
    const totalPriority = this.buffer.reduce((sum, s) => sum + s.priority, 0);
    const probabilities = this.buffer.map(s => s.priority / totalPriority);

    // Sample indices based on probabilities
    const indices: number[] = [];
    while (indices.length < actualBatchSize) {
      const r = Math.random();
      let cumProb = 0;
      for (let i = 0; i < this.buffer.length; i++) {
        cumProb += probabilities[i];
        if (r <= cumProb && !indices.includes(i)) {
          indices.push(i);
          break;
        }
      }
      // Fallback: add random index not already selected
      if (indices.length < actualBatchSize) {
        for (let i = 0; i < this.buffer.length; i++) {
          if (!indices.includes(i)) {
            indices.push(i);
            break;
          }
        }
      }
    }

    // Calculate importance sampling weights
    const maxWeight = Math.pow(this.buffer.length * Math.min(...probabilities), -this.beta);
    const weights = indices.map(i => {
      const weight = Math.pow(this.buffer.length * probabilities[i], -this.beta);
      return weight / maxWeight;
    });

    const samples = indices.map(i => this.buffer[i]);

    // Increment beta towards 1
    this.beta = Math.min(1.0, this.beta + this.betaIncrement);

    return { samples, weights, indices };
  }

  /**
   * Update priorities after learning
   */
  updatePriorities(indices: number[], tdErrors: number[]): void {
    for (let i = 0; i < indices.length; i++) {
      if (indices[i] < this.buffer.length) {
        this.buffer[indices[i]].priority = (Math.abs(tdErrors[i]) + 0.01) ** this.alpha;
      }
    }
  }

  /**
   * Get buffer size
   */
  size(): number {
    return this.buffer.length;
  }

  /**
   * Get buffer statistics
   */
  getStats(): {
    size: number;
    avgPriority: number;
    avgReward: number;
    avgPredictionError: number;
  } {
    if (this.buffer.length === 0) {
      return { size: 0, avgPriority: 0, avgReward: 0, avgPredictionError: 0 };
    }

    return {
      size: this.buffer.length,
      avgPriority: this.buffer.reduce((sum, s) => sum + s.priority, 0) / this.buffer.length,
      avgReward: this.buffer.reduce((sum, s) => sum + s.reward, 0) / this.buffer.length,
      avgPredictionError: this.buffer.reduce(
        (sum, s) => sum + Math.abs(s.predictedSINR - s.actualSINR),
        0
      ) / this.buffer.length,
    };
  }

  /**
   * Export buffer for persistence
   */
  export(): ExperienceSample[] {
    return [...this.buffer];
  }

  /**
   * Import buffer from persistence
   */
  import(samples: ExperienceSample[]): void {
    this.buffer = samples.slice(0, this.maxSize);
  }
}

// ============================================================================
// DIFFERENTIABLE SEARCH FOR OPTIMIZATION
// ============================================================================

/**
 * Differentiable search with soft attention for parameter optimization
 *
 * Instead of hard selection, uses temperature-controlled softmax
 * to enable gradient flow through the search process.
 */
export class DifferentiableParameterSearch {
  private temperature: number;
  private candidateEmbeddings: number[][] = [];
  private candidateParams: PowerControlParams[] = [];

  constructor(temperature: number = 1.0) {
    this.temperature = temperature;
  }

  /**
   * Generate candidate parameter space
   */
  generateCandidates(
    currentParams: PowerControlParams,
    config: SurrogateModelConfig
  ): PowerControlParams[] {
    const candidates: PowerControlParams[] = [];
    const { p0Range, alphaValues } = config;

    // Generate grid of candidates
    for (let p0 = p0Range.min; p0 <= p0Range.max; p0 += p0Range.step * 2) {
      for (const alpha of alphaValues) {
        candidates.push({ p0, alpha });
      }
    }

    // Add local refinement candidates around current
    for (let dp0 = -3; dp0 <= 3; dp0++) {
      const p0 = Math.max(p0Range.min, Math.min(p0Range.max, currentParams.p0 + dp0));
      for (const alpha of alphaValues) {
        if (!candidates.some(c => c.p0 === p0 && c.alpha === alpha)) {
          candidates.push({ p0, alpha });
        }
      }
    }

    this.candidateParams = candidates;
    return candidates;
  }

  /**
   * Embed candidates for search
   */
  embedCandidates(
    candidates: PowerControlParams[],
    predictor: (params: PowerControlParams) => number
  ): void {
    this.candidateParams = candidates;
    this.candidateEmbeddings = candidates.map(params => {
      const predictedSINR = predictor(params);
      // Embedding: [normalized P0, alpha, predicted SINR]
      return [
        (params.p0 + 110) / 25, // Normalize P0 to [0, 1]
        params.alpha,
        (predictedSINR + 5) / 35, // Normalize SINR to [0, 1]
      ];
    });
  }

  /**
   * Soft attention search - returns weighted combination
   */
  softSearch(queryEmbedding: number[]): {
    params: PowerControlParams;
    confidence: number;
    attention: number[];
  } {
    if (this.candidateEmbeddings.length === 0) {
      return {
        params: { p0: -100, alpha: 0.8 },
        confidence: 0,
        attention: [],
      };
    }

    // Compute attention scores
    const scores = this.candidateEmbeddings.map(emb => {
      let similarity = 0;
      for (let i = 0; i < queryEmbedding.length && i < emb.length; i++) {
        similarity += queryEmbedding[i] * emb[i];
      }
      return similarity / this.temperature;
    });

    // Softmax
    const maxScore = Math.max(...scores);
    const expScores = scores.map(s => Math.exp(s - maxScore));
    const sumExp = expScores.reduce((a, b) => a + b, 1e-9);
    const attention = expScores.map(s => s / sumExp);

    // Weighted combination of parameters
    let weightedP0 = 0;
    let weightedAlpha = 0;
    for (let i = 0; i < attention.length; i++) {
      weightedP0 += attention[i] * this.candidateParams[i].p0;
      weightedAlpha += attention[i] * this.candidateParams[i].alpha;
    }

    // Round P0 to valid value, snap alpha to nearest valid
    const validAlphas = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0];
    const snappedAlpha = validAlphas.reduce((prev, curr) =>
      Math.abs(curr - weightedAlpha) < Math.abs(prev - weightedAlpha) ? curr : prev
    );

    const confidence = Math.max(...attention);

    return {
      params: {
        p0: Math.round(weightedP0),
        alpha: snappedAlpha,
      },
      confidence,
      attention,
    };
  }

  /**
   * Hard search - returns best candidate
   */
  hardSearch(queryEmbedding: number[]): {
    params: PowerControlParams;
    score: number;
    index: number;
  } {
    if (this.candidateEmbeddings.length === 0) {
      return {
        params: { p0: -100, alpha: 0.8 },
        score: 0,
        index: -1,
      };
    }

    let bestScore = -Infinity;
    let bestIndex = 0;

    for (let i = 0; i < this.candidateEmbeddings.length; i++) {
      let score = 0;
      for (let j = 0; j < queryEmbedding.length && j < this.candidateEmbeddings[i].length; j++) {
        score += queryEmbedding[j] * this.candidateEmbeddings[i][j];
      }
      if (score > bestScore) {
        bestScore = score;
        bestIndex = i;
      }
    }

    return {
      params: this.candidateParams[bestIndex],
      score: bestScore,
      index: bestIndex,
    };
  }

  /**
   * Adjust temperature for exploration/exploitation
   */
  setTemperature(temperature: number): void {
    this.temperature = Math.max(0.01, temperature);
  }
}

// ============================================================================
// INTERFERENCE-AWARE CANDIDATE GENERATOR
// ============================================================================

/**
 * Cell profile for interference-aware candidate generation
 */
export interface CellProfile {
  currentSINR: number;
  currentIoT: number;
  neighborCount: number;
  avgNeighborIoT: number;
  isHighInterferenceSource: boolean;
  isCritical: boolean;
}

/**
 * Interference-aware candidate generation for bi-directional exploration
 *
 * This class addresses the "local minimum" problem where all P0 values
 * increase, by generating candidates that explore BOTH directions:
 * - High-interference cells: explore P0 DECREASES
 * - Low-SINR cells: explore P0 INCREASES
 * - Balanced cells: explore around optimal operating points
 */
export class InterferenceAwareCandidateGenerator {
  private config: SurrogateModelConfig;

  constructor(config: SurrogateModelConfig) {
    this.config = config;
  }

  /**
   * Generate candidates based on cell's interference profile
   */
  generateCandidates(
    currentParams: PowerControlParams,
    cellProfile: CellProfile
  ): PowerControlParams[] {
    const candidates: PowerControlParams[] = [];
    const { p0Range } = this.config;

    // Always include current params as baseline
    candidates.push({ ...currentParams });

    // HIGH INTERFERENCE CELL: Explore P0 DECREASES
    // This is the key fix - cells causing high IoT should try LOWER power
    if (cellProfile.isHighInterferenceSource || cellProfile.currentIoT > 12) {
      candidates.push(...this.generateLowInterferenceCandidates(currentParams, p0Range));
    }

    // LOW SINR / CRITICAL CELL: Explore P0 INCREASES
    if (cellProfile.currentSINR < 5 || cellProfile.isCritical) {
      candidates.push(...this.generateHighPowerCandidates(currentParams, p0Range));
    }

    // BALANCED CELL: Explore around optimal operating points
    if (cellProfile.currentSINR >= 5 && cellProfile.currentIoT <= 10) {
      candidates.push(...this.generateBalancedCandidates(currentParams, p0Range));
    }

    // Always add Ericsson optimal configs
    candidates.push(...this.getEricssonOptimalConfigs());

    return this.deduplicateCandidates(candidates);
  }

  /**
   * Generate low-interference candidates (P0 DECREASES)
   * For cells that are causing high interference to neighbors
   */
  private generateLowInterferenceCandidates(
    current: PowerControlParams,
    p0Range: { min: number; max: number; step: number }
  ): PowerControlParams[] {
    const candidates: PowerControlParams[] = [];

    // P0 DECREASES: -2 to -10 dB from current
    for (let dp0 = -2; dp0 >= -10; dp0 -= 2) {
      const p0 = Math.max(p0Range.min, current.p0 + dp0);
      for (const alpha of [0.5, 0.6, 0.7]) {
        candidates.push({ p0, alpha });
      }
    }

    // Ultra-conservative configs for high-interference scenarios
    candidates.push({ p0: -105, alpha: 0.6 });
    candidates.push({ p0: -108, alpha: 0.5 });
    candidates.push({ p0: -110, alpha: 0.4 });

    return candidates;
  }

  /**
   * Generate high-power candidates (P0 INCREASES)
   * For cells with low SINR that need more power
   */
  private generateHighPowerCandidates(
    current: PowerControlParams,
    p0Range: { min: number; max: number; step: number }
  ): PowerControlParams[] {
    const candidates: PowerControlParams[] = [];

    // P0 INCREASES: +2 to +8 dB from current
    for (let dp0 = 2; dp0 <= 8; dp0 += 2) {
      const p0 = Math.min(p0Range.max, current.p0 + dp0);
      for (const alpha of [0.8, 0.9, 1.0]) {
        candidates.push({ p0, alpha });
      }
    }

    // Aggressive configs for cell-edge / critical cells
    candidates.push({ p0: -90, alpha: 1.0 });
    candidates.push({ p0: -88, alpha: 1.0 });
    candidates.push({ p0: -92, alpha: 0.9 });

    return candidates;
  }

  /**
   * Generate balanced candidates
   * For cells that are already in a good state
   */
  private generateBalancedCandidates(
    current: PowerControlParams,
    p0Range: { min: number; max: number; step: number }
  ): PowerControlParams[] {
    const candidates: PowerControlParams[] = [];

    // Both directions with moderate alpha
    for (let dp0 = -4; dp0 <= 4; dp0 += 2) {
      const p0 = Math.max(p0Range.min, Math.min(p0Range.max, current.p0 + dp0));
      for (const alpha of [0.7, 0.8, 0.9]) {
        candidates.push({ p0, alpha });
      }
    }

    return candidates;
  }

  /**
   * Ericsson-recommended optimal configurations
   */
  private getEricssonOptimalConfigs(): PowerControlParams[] {
    return [
      { p0: -100, alpha: 0.8 }, // Nominal balanced
      { p0: -98, alpha: 0.8 }, // Slightly higher power
      { p0: -102, alpha: 0.7 }, // Conservative
      { p0: -105, alpha: 0.7 }, // Very conservative
      { p0: -96, alpha: 0.9 }, // Aggressive cell-edge
      { p0: -108, alpha: 0.6 }, // Ultra-conservative
    ];
  }

  /**
   * Remove duplicate candidates
   */
  private deduplicateCandidates(candidates: PowerControlParams[]): PowerControlParams[] {
    const seen = new Set<string>();
    return candidates.filter(c => {
      const key = `${c.p0}_${c.alpha}`;
      if (seen.has(key)) return false;
      seen.add(key);
      return true;
    });
  }
}

// ============================================================================
// SELF-LEARNING GNN FOR UPLINK OPTIMIZATION
// ============================================================================

/**
 * Self-Learning GNN for Ericsson Uplink Optimization
 *
 * This is the main class that integrates all components for self-learning
 * P0 Nominal PUSCH and Alpha parameter optimization.
 *
 * Key capabilities:
 * - RuVector GNN layers for prediction
 * - Experience replay for continuous learning
 * - Differentiable search for parameter optimization
 * - Adaptive learning rate and exploration
 * - Model checkpointing and persistence
 */
export class SelfLearningUplinkGNN {
  private config: SurrogateModelConfig;
  private gnnLayer: RuVectorGNNLayer;
  private mlpLayer1: RuVectorGNNLayer;
  private mlpLayer2: RuVectorGNNLayer;
  private replayBuffer: ExperienceReplayBuffer;
  private parameterSearch: DifferentiableParameterSearch;
  private graphBuilder: SurrogateGraphBuilder;
  private issueDetector: IssueCellDetector;

  // Learning state
  private state: SelfLearningState;
  private targetNetwork: RuVectorGNNLayer | null = null;
  private updateCounter: number = 0;
  private targetUpdateFrequency: number = 100;

  constructor(config: Partial<SurrogateModelConfig> = {}) {
    this.config = { ...DEFAULT_SURROGATE_CONFIG, ...config };

    // Initialize RuVector GNN layers
    this.gnnLayer = new RuVectorGNNLayer({
      inputDim: this.config.inputDim,
      hiddenDim: this.config.hiddenDim,
      numHeads: this.config.numHeads,
      dropout: 0.1,
    });

    // MLP layers for prediction head
    this.mlpLayer1 = new RuVectorGNNLayer({
      inputDim: this.config.hiddenDim,
      hiddenDim: this.config.hiddenDim,
      numHeads: 1,
      dropout: 0.05,
    });

    this.mlpLayer2 = new RuVectorGNNLayer({
      inputDim: this.config.hiddenDim,
      hiddenDim: 2, // Output: [SINR, IoT]
      numHeads: 1,
      dropout: 0,
    });

    // Initialize experience replay
    this.replayBuffer = new ExperienceReplayBuffer(10000, 0.6, 0.4, 0.001);

    // Initialize differentiable search
    this.parameterSearch = new DifferentiableParameterSearch(1.0);

    // Initialize graph builder and issue detector
    this.graphBuilder = new SurrogateGraphBuilder(this.config);
    this.issueDetector = new IssueCellDetector(this.config);

    // Initialize learning state
    this.state = {
      modelVersion: 1,
      totalSamples: 0,
      totalUpdates: 0,
      avgLoss: 0,
      avgReward: 0,
      learningRate: this.config.training.learningRate,
      explorationRate: 0.3,
      lastCheckpoint: null,
      metrics: {
        sinrPredictionError: 0,
        optimizationSuccessRate: 0,
        avgSINRImprovement: 0,
        neighborImpactScore: 0,
        convergenceScore: 0,
        adaptationRate: 0,
      },
    };
  }

  /**
   * Forward pass: Predict SINR and IoT for all cells
   *
   * The prediction uses a physics-informed approach with proper interference modeling:
   * - Base SINR is derived from node features (normalized SINR from snapshot)
   * - P0 and Alpha adjustments modify the prediction
   * - GNN embeddings capture neighbor interference effects
   * - Higher P0 improves own cell but increases interference to neighbors (tradeoff)
   * - Optimal P0/Alpha depends on network topology and neighbor configuration
   */
  predict(graph: SurrogateGraph): {
    sinr: number[];
    iot: number[];
    embeddings: number[][];
  } {
    // GNN message passing for neighbor interference modeling
    const embeddings = this.gnnLayer.forward(
      graph.nodeFeatures,
      graph.adjacencyMatrix,
      graph.edgeFeatures
    );

    const numNodes = graph.nodeIds.length;
    const sinr: number[] = [];
    const iot: number[] = [];

    // First pass: calculate base parameters and aggregate neighbor power levels
    const cellPowerLevels: number[] = [];
    for (let i = 0; i < numNodes; i++) {
      const cellId = graph.nodeIds[i];
      const params = graph.powerParams.get(cellId)!;
      // Effective transmit power proxy based on P0 and Alpha
      const effectivePower = params.p0 + 110 + (params.alpha - 0.5) * 10;
      cellPowerLevels.push(effectivePower);
    }

    // Second pass: compute SINR and IoT with neighbor interference
    for (let i = 0; i < numNodes; i++) {
      const features = graph.nodeFeatures[i];
      const cellId = graph.nodeIds[i];
      const params = graph.powerParams.get(cellId)!;

      // Extract key features from node feature vector
      // Features[0] = normalized P0, Features[1] = alpha
      // Features[2] = normalized ulSinrAvg (base SINR from snapshot)
      // Features[8] = normalized IoT
      const baseSinrNorm = features[2]; // (sinr + 5) / 35
      const baseIotNorm = features[8]; // iot / 20

      // De-normalize base values
      const baseSinr = baseSinrNorm * 35 - 5;
      const baseIot = baseIotNorm * 20;

      // Calculate own cell's power contribution to SINR
      // Higher P0 (less negative) = higher UE transmit power = better received signal
      // P0 effects are subtle - each dB change gives ~0.15-0.2 dB SINR gain
      const p0Delta = params.p0 - (-100); // Delta from nominal -100 dBm
      const p0Effect = p0Delta * 0.18; // Linear with moderate gain

      // Alpha effect: higher alpha = more path loss compensation
      // Optimal around 0.7-0.8 for typical deployments
      // Alpha has stronger effect on cell-edge SINR
      const alphaOptimal = 0.8;
      const alphaDelta = params.alpha - alphaOptimal;
      const alphaEffect = alphaDelta * 2.5; // More alpha = better coverage

      // Calculate inter-cell interference received from neighbors
      // Neighbors with high P0/Alpha increase our IoT
      let neighborInterference = 0;
      let neighborCount = 0;
      for (let j = 0; j < numNodes; j++) {
        if (i !== j && graph.adjacencyMatrix[i][j] > 0.1) {
          const coupling = graph.adjacencyMatrix[i][j];
          neighborInterference += cellPowerLevels[j] * coupling * 0.08;
          neighborCount++;
        }
      }
      if (neighborCount > 0) {
        neighborInterference /= Math.sqrt(neighborCount); // Sub-linear scaling
      }

      // GNN embedding contribution (learned interference patterns)
      const embedding = embeddings[i];
      const gnnInfluence = embedding.slice(0, 8).reduce((a, b) => a + b, 0) / 8;
      const learnedInterference = gnnInfluence * 0.3;

      // Final SINR prediction
      // = base SINR + P0 benefit + Alpha benefit - interference effects
      let predictedSinr = baseSinr + p0Effect + alphaEffect - neighborInterference - learnedInterference;

      // IoT prediction: scales with neighbor interference
      // Own cell P0 doesn't directly affect own IoT (it affects neighbors' IoT)
      let predictedIot = baseIot + neighborInterference * 0.5;

      // Bonus for balanced configurations (network-friendly settings)
      if (params.p0 >= -102 && params.p0 <= -95 && params.alpha >= 0.7 && params.alpha <= 0.9) {
        predictedSinr += 0.8; // Bonus for network-optimal config
        predictedIot -= 0.4;
      }

      // Clamp to valid ranges
      predictedSinr = Math.max(-5, Math.min(30, isNaN(predictedSinr) ? baseSinr : predictedSinr));
      predictedIot = Math.max(0, Math.min(20, isNaN(predictedIot) ? baseIot : predictedIot));

      sinr.push(predictedSinr);
      iot.push(predictedIot);
    }

    return { sinr, iot, embeddings };
  }

  /**
   * Optimize a cell's P0/Alpha parameters using self-learning
   *
   * Uses exhaustive search with fitness evaluation considering:
   * - Own cell SINR improvement
   * - Neighbor SINR impact (degradation penalty)
   * - IoT change
   * - Achieving healthy status
   */
  optimizeCell(
    cellId: string,
    graph: SurrogateGraph,
    cellSnapshots: Map<string, CellKPISnapshot>,
    neighborRelations: NeighborRelation[]
  ): CellOptimizationResult {
    const cellIdx = graph.nodeIds.indexOf(cellId);
    if (cellIdx < 0) {
      throw new Error(`Cell ${cellId} not found in graph`);
    }

    const snapshot = cellSnapshots.get(cellId)!;
    const currentParams = graph.powerParams.get(cellId)!;
    const neighbors = this.issueDetector.getNeighbors(cellId, neighborRelations);
    const neighborIndices = neighbors
      .map(nid => graph.nodeIds.indexOf(nid))
      .filter(idx => idx >= 0);

    // Baseline prediction
    const baselinePred = this.predict(graph);
    const baselineSINR = baselinePred.sinr[cellIdx];
    const baselineIoT = baselinePred.iot[cellIdx];
    const baselineNeighborSINRs = neighborIndices.map(idx => baselinePred.sinr[idx]);
    const avgBaselineNeighborSINR = baselineNeighborSINRs.length > 0
      ? baselineNeighborSINRs.reduce((a, b) => a + b, 0) / baselineNeighborSINRs.length
      : 0;

    // Build cell profile for interference-aware candidate generation
    const cellProfile = this.buildCellProfile(
      cellId,
      graph,
      cellSnapshots,
      neighborRelations,
      baselinePred
    );

    // Generate candidates using interference-aware generator (bi-directional exploration)
    const candidateGenerator = new InterferenceAwareCandidateGenerator(this.config);
    const candidates = candidateGenerator.generateCandidates(currentParams, cellProfile);

    // Exhaustive search: evaluate all candidates with fitness function
    let bestParams = { ...currentParams };
    let bestFitness = -Infinity;
    let bestSINR = baselineSINR;
    let bestIoT = baselineIoT;
    let bestNeighborImpact = 0;

    for (const candidate of candidates) {
      // Predict with candidate parameters
      const updatedGraph = this.graphBuilder.updateGraphParams(
        graph,
        new Map([[cellId, candidate]]),
        cellSnapshots
      );
      const pred = this.predict(updatedGraph);

      const candidateSINR = pred.sinr[cellIdx];
      const candidateIoT = pred.iot[cellIdx];
      const candidateNeighborSINRs = neighborIndices.map(idx => pred.sinr[idx]);
      const avgCandidateNeighborSINR = candidateNeighborSINRs.length > 0
        ? candidateNeighborSINRs.reduce((a, b) => a + b, 0) / candidateNeighborSINRs.length
        : 0;

      const sinrImprovement = candidateSINR - baselineSINR;
      const neighborDegradation = avgBaselineNeighborSINR - avgCandidateNeighborSINR;
      const iotChange = candidateIoT - baselineIoT;

      // Fitness function considering all factors
      const fitness = this.calculateOptimizationFitness(
        sinrImprovement,
        neighborDegradation,
        candidateSINR,
        iotChange
      );

      if (fitness > bestFitness) {
        bestFitness = fitness;
        bestParams = candidate;
        bestSINR = candidateSINR;
        bestIoT = candidateIoT;
        bestNeighborImpact = avgCandidateNeighborSINR - avgBaselineNeighborSINR;
      }
    }

    // Add exploration: occasionally try a random candidate
    if (Math.random() < this.state.explorationRate * 0.3) {
      const randomCandidate = candidates[Math.floor(Math.random() * candidates.length)];
      const updatedGraph = this.graphBuilder.updateGraphParams(
        graph,
        new Map([[cellId, randomCandidate]]),
        cellSnapshots
      );
      const pred = this.predict(updatedGraph);
      const randomSINR = pred.sinr[cellIdx];
      if (randomSINR > bestSINR + 0.5) {
        bestParams = randomCandidate;
        bestSINR = randomSINR;
        bestIoT = pred.iot[cellIdx];
        const neighborSINRs = neighborIndices.map(idx => pred.sinr[idx]);
        bestNeighborImpact = neighborSINRs.length > 0
          ? neighborSINRs.reduce((a, b) => a + b, 0) / neighborSINRs.length - avgBaselineNeighborSINR
          : 0;
      }
    }

    // Confidence based on improvement magnitude
    const confidence = Math.min(0.95, 0.5 + (bestSINR - baselineSINR) * 0.1);

    // Calculate status transition
    const statusBefore = this.getStatus(baselineSINR, baselineIoT, snapshot);
    const statusAfter = this.getStatus(bestSINR, bestIoT, snapshot);
    const scoreBefore = this.calculateScore(baselineSINR, baselineIoT);
    const scoreAfter = this.calculateScore(bestSINR, bestIoT);

    // Decay exploration rate
    this.state.explorationRate = Math.max(0.05, this.state.explorationRate * 0.999);

    return {
      cellId,
      originalParams: currentParams,
      optimizedParams: bestParams,
      originalSINR: baselineSINR,
      optimizedSINR: bestSINR,
      sinrImprovement: bestSINR - baselineSINR,
      neighborImpact: bestNeighborImpact,
      iterations: candidates.length,
      confidence,
      statusTransition: {
        before: statusBefore,
        after: statusAfter,
        scoreBefore,
        scoreAfter,
      },
    };
  }

  /**
   * Generate candidate parameters with focus on optimal operating range
   * @deprecated Use InterferenceAwareCandidateGenerator instead
   */
  private generateOptimalCandidates(current: PowerControlParams): PowerControlParams[] {
    const candidates: PowerControlParams[] = [];
    const { p0Range, alphaValues } = this.config;

    // Local search around current values
    for (let dp0 = -6; dp0 <= 6; dp0 += 2) {
      const p0 = current.p0 + dp0;
      if (p0 >= p0Range.min && p0 <= p0Range.max) {
        for (const alpha of alphaValues) {
          candidates.push({ p0, alpha });
        }
      }
    }

    // Optimal operating points (Ericsson recommendations)
    const optimalConfigs = [
      { p0: -100, alpha: 0.8 },  // Nominal balanced
      { p0: -98, alpha: 0.8 },   // Slightly higher power
      { p0: -102, alpha: 0.7 },  // Conservative low interference
      { p0: -96, alpha: 0.9 },   // Aggressive for cell-edge
      { p0: -100, alpha: 0.7 },  // Balanced with lower alpha
      { p0: -95, alpha: 0.8 },   // Higher power balanced
      { p0: -105, alpha: 0.6 },  // Very conservative
    ];
    for (const config of optimalConfigs) {
      if (!candidates.some(c => c.p0 === config.p0 && c.alpha === config.alpha)) {
        candidates.push(config);
      }
    }

    return candidates;
  }

  /**
   * Build a cell profile for interference-aware candidate generation
   *
   * Analyzes cell's current state to determine:
   * - Whether it's a high-interference source (should try lower power)
   * - Whether it's critical (needs aggressive optimization)
   * - Neighbor interference characteristics
   */
  buildCellProfile(
    cellId: string,
    graph: SurrogateGraph,
    cellSnapshots: Map<string, CellKPISnapshot>,
    neighborRelations: NeighborRelation[],
    predictions: { sinr: number[]; iot: number[] }
  ): CellProfile {
    const cellIdx = graph.nodeIds.indexOf(cellId);
    const snapshot = cellSnapshots.get(cellId)!;
    const neighbors = this.issueDetector.getNeighbors(cellId, neighborRelations);
    const currentParams = graph.powerParams.get(cellId)!;

    // Calculate average neighbor IoT
    let avgNeighborIoT = 0;
    let neighborCount = 0;
    for (const neighborId of neighbors) {
      const neighborSnapshot = cellSnapshots.get(neighborId);
      if (neighborSnapshot) {
        avgNeighborIoT += neighborSnapshot.uplinkInterference.iotAvg;
        neighborCount++;
      }
    }
    avgNeighborIoT = neighborCount > 0 ? avgNeighborIoT / neighborCount : 0;

    // Determine if cell is a high-interference source
    // Criteria: high own IoT, high neighbor IoT, and high P0 (aggressive settings)
    const ownIoT = snapshot.uplinkInterference.iotAvg;
    const isHighInterferenceSource =
      ownIoT > 10 && avgNeighborIoT > 8 && currentParams.p0 > -98;

    // Determine if cell is critical
    const isCritical = predictions.sinr[cellIdx] < 0;

    return {
      currentSINR: predictions.sinr[cellIdx],
      currentIoT: predictions.iot[cellIdx],
      neighborCount,
      avgNeighborIoT,
      isHighInterferenceSource,
      isCritical,
    };
  }

  /**
   * Calculate fitness for optimization with proper tradeoff handling
   */
  private calculateOptimizationFitness(
    sinrImprovement: number,
    neighborDegradation: number,
    absoluteSINR: number,
    iotChange: number
  ): number {
    let fitness = 0;

    // Primary: SINR improvement (0.4 weight)
    fitness += sinrImprovement * 0.4;

    // Bonus for achieving good SINR levels
    if (absoluteSINR > 5) fitness += 0.5;  // Above issue threshold
    if (absoluteSINR > 10) fitness += 0.3; // Good SINR
    if (absoluteSINR > 15) fitness += 0.2; // Excellent SINR

    // Penalty for neighbor degradation (critical for network-wide optimization)
    if (neighborDegradation > 0) {
      fitness -= neighborDegradation * 0.5;
    }
    if (neighborDegradation > 2) {
      fitness -= (neighborDegradation - 2) * 0.3; // Extra penalty for significant degradation
    }

    // Penalty for IoT increase
    if (iotChange > 0) {
      fitness -= iotChange * 0.2;
    }
    if (iotChange > 3) {
      fitness -= (iotChange - 3) * 0.3; // Extra penalty for large IoT increase
    }

    // Penalty if still in critical/issue range
    if (absoluteSINR < 0) fitness -= 0.5;
    else if (absoluteSINR < 5) fitness -= 0.2;

    return fitness;
  }

  /**
   * Learn from actual network feedback (online learning)
   *
   * Enhanced version with optional IoT and neighbor SINR measurements
   * for multi-objective reward calculation.
   */
  learnFromFeedback(
    graph: SurrogateGraph,
    cellId: string,
    appliedParams: PowerControlParams,
    actualSINR: number,
    actualIoT?: number,
    neighborSINRs?: Map<string, number>
  ): { loss: number; reward: number } {
    const cellIdx = graph.nodeIds.indexOf(cellId);
    if (cellIdx < 0) {
      return { loss: 0, reward: 0 };
    }

    // Get prediction for the applied parameters
    const updatedGraph = new SurrogateGraphBuilder(this.config).updateGraphParams(
      graph,
      new Map([[cellId, appliedParams]]),
      new Map() // Empty snapshots - use existing features
    );
    const pred = this.predict(updatedGraph);
    const predictedSINR = pred.sinr[cellIdx];
    const predictedIoT = pred.iot[cellIdx];

    // Calculate IoT change (if actual IoT provided)
    const iotIncrease = actualIoT !== undefined ? actualIoT - predictedIoT : 0;

    // Calculate neighbor impact (if neighbor SINRs provided)
    let neighborSINRDelta = 0;
    if (neighborSINRs && neighborSINRs.size > 0) {
      const neighborIndices = graph.nodeIds
        .map((id, idx) => ({ id, idx }))
        .filter(({ id }) => neighborSINRs.has(id))
        .map(({ idx }) => idx);

      if (neighborIndices.length > 0) {
        const baselineNeighborSINR =
          neighborIndices.map(idx => pred.sinr[idx]).reduce((a, b) => a + b, 0) /
          neighborIndices.length;
        const actualNeighborSINR =
          Array.from(neighborSINRs.values()).reduce((a, b) => a + b, 0) /
          neighborSINRs.size;
        neighborSINRDelta = actualNeighborSINR - baselineNeighborSINR;
      }
    }

    // Calculate multi-objective reward using new function
    const reward = this.calculateReward(
      actualSINR,
      predictedSINR,
      iotIncrease,
      neighborSINRDelta
    );

    // Calculate prediction error for loss
    const predictionError = Math.abs(predictedSINR - actualSINR);

    // Add to replay buffer
    this.replayBuffer.add({
      timestamp: new Date(),
      graph,
      cellId,
      params: appliedParams,
      predictedSINR,
      actualSINR,
      reward,
    });

    this.state.totalSamples++;

    // Train on batch from replay buffer
    const batchSize = Math.min(32, this.replayBuffer.size());
    if (batchSize > 8) {
      const loss = this.trainOnBatch(batchSize);
      return { loss, reward };
    }

    return { loss: predictionError, reward };
  }

  /**
   * Train on a batch from the replay buffer
   *
   * Enhanced with:
   * - Minimum sample threshold (don't train with too few samples)
   * - Learning rate scheduling (decay every 500 updates)
   */
  trainOnBatch(batchSize: number): number {
    // Minimum samples threshold - don't train with too few samples
    const minSamplesForTraining = 50;
    if (this.replayBuffer.size() < minSamplesForTraining) {
      return 0; // Wait for more samples before training
    }

    const { samples, weights, indices } = this.replayBuffer.sample(batchSize);

    if (samples.length === 0) {
      return 0;
    }

    this.gnnLayer.setTraining(true);
    this.mlpLayer1.setTraining(true);

    let totalLoss = 0;
    const tdErrors: number[] = [];

    for (let i = 0; i < samples.length; i++) {
      const sample = samples[i];
      const weight = weights[i];

      // Get prediction
      const pred = this.predict(sample.graph);
      const cellIdx = sample.graph.nodeIds.indexOf(sample.cellId);
      if (cellIdx < 0) continue;

      const predictedSINR = pred.sinr[cellIdx];
      const error = predictedSINR - sample.actualSINR;
      const loss = error * error * weight;
      totalLoss += loss;
      tdErrors.push(error);

      // Compute gradients (simplified)
      const gradScale = 2 * error * weight * this.state.learningRate;

      // Update GNN layer (simplified gradient)
      const gradients = this.computeSimplifiedGradients(gradScale, pred.embeddings[cellIdx]);
      this.gnnLayer.updateWeights(gradients, this.state.learningRate);
    }

    // Update priorities in replay buffer
    this.replayBuffer.updatePriorities(indices, tdErrors);

    this.gnnLayer.setTraining(false);
    this.mlpLayer1.setTraining(false);

    // Update learning state
    this.state.totalUpdates++;
    this.state.avgLoss = 0.9 * this.state.avgLoss + 0.1 * (totalLoss / samples.length);
    this.state.avgReward = 0.9 * this.state.avgReward +
      0.1 * (samples.reduce((sum, s) => sum + s.reward, 0) / samples.length);

    // Learning rate scheduling: decay every 500 updates
    if (this.state.totalUpdates % 500 === 0 && this.state.totalUpdates > 0) {
      this.state.learningRate = Math.max(1e-6, this.state.learningRate * 0.9);
    }

    // Also apply gradual decay
    this.state.learningRate = Math.max(1e-6, this.state.learningRate * 0.9999);

    // Update target network periodically
    this.updateCounter++;
    if (this.updateCounter % this.targetUpdateFrequency === 0) {
      this.updateTargetNetwork();
    }

    return totalLoss / samples.length;
  }

  /**
   * Get current learning state
   */
  getState(): SelfLearningState {
    return { ...this.state };
  }

  /**
   * Get learning metrics
   */
  getMetrics(): LearningMetrics {
    const bufferStats = this.replayBuffer.getStats();

    return {
      sinrPredictionError: bufferStats.avgPredictionError,
      optimizationSuccessRate: bufferStats.avgReward > 0.5 ? 0.8 : 0.5,
      avgSINRImprovement: this.state.avgReward * 3, // Scale to dB
      neighborImpactScore: 0.9, // Placeholder
      convergenceScore: Math.max(0, 1 - this.state.avgLoss),
      adaptationRate: this.state.learningRate / this.config.training.learningRate,
    };
  }

  /**
   * Export model checkpoint
   */
  checkpoint(): {
    version: number;
    gnnWeights: ReturnType<RuVectorGNNLayer['exportWeights']>;
    mlp1Weights: ReturnType<RuVectorGNNLayer['exportWeights']>;
    mlp2Weights: ReturnType<RuVectorGNNLayer['exportWeights']>;
    state: SelfLearningState;
    replayBuffer: ExperienceSample[];
  } {
    this.state.lastCheckpoint = new Date();
    this.state.modelVersion++;

    return {
      version: this.state.modelVersion,
      gnnWeights: this.gnnLayer.exportWeights(),
      mlp1Weights: this.mlpLayer1.exportWeights(),
      mlp2Weights: this.mlpLayer2.exportWeights(),
      state: { ...this.state },
      replayBuffer: this.replayBuffer.export(),
    };
  }

  /**
   * Restore model from checkpoint
   */
  restore(checkpoint: {
    version: number;
    gnnWeights: ReturnType<RuVectorGNNLayer['exportWeights']>;
    mlp1Weights: ReturnType<RuVectorGNNLayer['exportWeights']>;
    mlp2Weights: ReturnType<RuVectorGNNLayer['exportWeights']>;
    state: SelfLearningState;
    replayBuffer: ExperienceSample[];
  }): void {
    this.gnnLayer.importWeights(checkpoint.gnnWeights);
    this.mlpLayer1.importWeights(checkpoint.mlp1Weights);
    this.mlpLayer2.importWeights(checkpoint.mlp2Weights);
    this.state = { ...checkpoint.state };
    this.replayBuffer.import(checkpoint.replayBuffer);
  }

  // Private helper methods

  private identityMatrix(size: number): number[][] {
    return Array(size)
      .fill(null)
      .map((_, i) =>
        Array(size)
          .fill(0)
          .map((_, j) => (i === j ? 1 : 0))
      );
  }

  /**
   * Calculate multi-objective reward with explicit IoT penalty
   *
   * This improved reward function provides:
   * - Continuous gradient (not binary) for better learning
   * - Explicit interference penalty to discourage trading SINR for IoT
   * - Neighbor impact consideration for network-wide optimization
   * - Prediction accuracy bonus to improve model quality
   */
  private calculateReward(
    actualSINR: number,
    predictedSINR: number,
    iotIncrease: number,
    neighborSINRDelta: number
  ): number {
    let reward = 0;

    // Primary: SINR quality (continuous gradient, not binary)
    if (actualSINR > 10) {
      reward += 1.0; // Excellent
    } else if (actualSINR > 5) {
      reward += 0.5 + (actualSINR - 5) * 0.1; // Good, gradient toward 10
    } else if (actualSINR > 0) {
      reward += 0.2 + actualSINR * 0.06; // Acceptable, gradient toward 5
    } else {
      reward += actualSINR * 0.1; // Penalty for negative SINR
    }

    // Interference penalty: penalize IoT increases
    if (iotIncrease > 2.0) {
      reward -= 0.4; // Significant IoT increase
    } else if (iotIncrease > 1.0) {
      reward -= 0.2; // Moderate IoT increase
    } else if (iotIncrease < -0.5) {
      reward += 0.15; // Bonus for reducing IoT
    }

    // Neighbor impact penalty
    if (neighborSINRDelta < -1.5) {
      reward -= 0.3; // Significant neighbor degradation
    } else if (neighborSINRDelta < -0.5) {
      reward -= 0.1; // Moderate neighbor degradation
    } else if (neighborSINRDelta > 0.5) {
      reward += 0.1; // Bonus for improving neighbors
    }

    // Prediction accuracy bonus (encourages model improvement)
    const predictionError = Math.abs(predictedSINR - actualSINR);
    if (predictionError < 1.0) {
      reward += 0.1;
    } else if (predictionError > 3.0) {
      reward -= 0.1;
    }

    return Math.max(-1.0, Math.min(1.5, reward));
  }

  private getStatus(
    sinr: number,
    iot: number,
    snapshot: CellKPISnapshot
  ): 'healthy' | 'warning' | 'issue' | 'critical' {
    const { thresholds } = this.config;

    if (sinr < thresholds.sinrCritical || iot > 15) {
      return 'critical';
    }
    if (sinr < thresholds.sinrLow || iot > thresholds.iotHigh) {
      return 'issue';
    }
    if (snapshot.uplinkPowerControl.powerLimitedUeRatio > thresholds.powerLimitedHigh) {
      return 'warning';
    }
    return 'healthy';
  }

  private calculateScore(sinr: number, iot: number): number {
    const sinrScore = Math.max(0, Math.min(20, (sinr + 5) * 0.7));
    const iotScore = Math.max(0, Math.min(10, (20 - iot) * 0.5));
    return Math.round(sinrScore + iotScore);
  }

  private computeSimplifiedGradients(
    gradScale: number,
    embedding: number[]
  ): {
    W_query: number[][];
    W_key: number[][];
    W_value: number[][];
    W_output: number[][];
  } {
    const { inputDim, hiddenDim } = this.config;

    // Simplified gradient computation
    const grad = Array(inputDim)
      .fill(null)
      .map(() => Array(hiddenDim).fill(gradScale * 0.01));

    return {
      W_query: grad,
      W_key: grad,
      W_value: grad,
      W_output: Array(hiddenDim)
        .fill(null)
        .map(() => Array(hiddenDim).fill(gradScale * 0.01)),
    };
  }

  private updateTargetNetwork(): void {
    // Clone current network as target
    this.targetNetwork = new RuVectorGNNLayer(this.gnnLayer.getConfig());
    this.targetNetwork.importWeights(this.gnnLayer.exportWeights());
  }
}

// ============================================================================
// ERICSSON-STYLE UPLINK OPTIMIZER
// ============================================================================

/**
 * Ericsson-style Uplink Optimizer using Self-Learning GNN
 *
 * This class provides a high-level interface for network optimization,
 * combining the self-learning GNN with production-ready features.
 */
export class EricssonUplinkOptimizer {
  private selfLearningGNN: SelfLearningUplinkGNN;
  private graphBuilder: SurrogateGraphBuilder;
  private issueDetector: IssueCellDetector;
  private config: SurrogateModelConfig;

  constructor(config: Partial<SurrogateModelConfig> = {}) {
    this.config = { ...DEFAULT_SURROGATE_CONFIG, ...config };
    this.selfLearningGNN = new SelfLearningUplinkGNN(this.config);
    this.graphBuilder = new SurrogateGraphBuilder(this.config);
    this.issueDetector = new IssueCellDetector(this.config);
  }

  /**
   * Optimize entire network
   */
  optimizeNetwork(
    cellSnapshots: Map<string, CellKPISnapshot>,
    neighborRelations: NeighborRelation[]
  ): {
    timestamp: Date;
    results: CellOptimizationResult[];
    metrics: LearningMetrics;
    recommendations: string[];
  } {
    const timestamp = new Date();

    // Build network graph
    const graph = this.graphBuilder.buildGraph(cellSnapshots, neighborRelations);

    // Detect issue cells
    const issueCells = this.issueDetector.detectIssueCells(cellSnapshots, neighborRelations);

    // Optimize each issue cell
    const results: CellOptimizationResult[] = [];

    for (const issueCell of issueCells) {
      try {
        const result = this.selfLearningGNN.optimizeCell(
          issueCell.cellId,
          graph,
          cellSnapshots,
          neighborRelations
        );

        if (result.sinrImprovement >= this.config.optimization.minImprovement) {
          results.push(result);
        }
      } catch {
        continue;
      }
    }

    // Generate recommendations
    const recommendations = this.generateRecommendations(results, issueCells);
    const metrics = this.selfLearningGNN.getMetrics();

    return { timestamp, results, metrics, recommendations };
  }

  /**
   * Optimize network using cluster-based multi-cell approach
   *
   * This method addresses the root cause of single-cell optimization limitations
   * by grouping interfering cells into clusters and optimizing them jointly.
   * Critical cells are prioritized with neighbor sacrifice strategies.
   */
async optimizeNetworkClustered(
    cellSnapshots: Map<string, CellKPISnapshot>,
    neighborRelations: NeighborRelation[]
  ): Promise<{
    timestamp: Date;
    clusterResults: Array<{
      clusterId: string;
      cellResults: CellOptimizationResult[];
      clusterSINRBefore: number;
      clusterSINRAfter: number;
      clusterImprovement: number;
      networkImpact: number;
      strategyUsed: string;
    }>;
    cellResults: CellOptimizationResult[];
    metrics: LearningMetrics;
    clusterMetrics: {
      totalClusters: number;
      criticalCellsInClusters: number;
      avgClusterImprovement: number;
      bestStrategy: string;
    };
    recommendations: string[];
  }> {
    // Import cluster optimizer dynamically to avoid circular dependencies
    const { NetworkClusterOptimizer } = await import('./cluster-optimizer.js');

    const clusterOptimizer = new NetworkClusterOptimizer(this.selfLearningGNN, this.config);
    const result = clusterOptimizer.optimizeNetwork(cellSnapshots, neighborRelations);

    // Find best performing strategy
    const strategyCounts = new Map<string, { count: number; totalImprovement: number }>();
    for (const cr of result.clusterResults) {
      const existing = strategyCounts.get(cr.strategyUsed) || { count: 0, totalImprovement: 0 };
      strategyCounts.set(cr.strategyUsed, {
        count: existing.count + 1,
        totalImprovement: existing.totalImprovement + cr.clusterImprovement,
      });
    }

    let bestStrategy = 'none';
    let bestAvgImprovement = -Infinity;
    for (const [strategy, stats] of strategyCounts) {
      const avgImprovement = stats.totalImprovement / stats.count;
      if (avgImprovement > bestAvgImprovement) {
        bestAvgImprovement = avgImprovement;
        bestStrategy = strategy;
      }
    }

    // Count critical cells in clusters
    const criticalCellsInClusters = result.clusters.reduce(
      (sum, c) => sum + c.criticalCellIds.length,
      0
    );

    return {
      timestamp: result.timestamp,
      clusterResults: result.clusterResults,
      cellResults: result.cellResults,
      metrics: this.selfLearningGNN.getMetrics(),
      clusterMetrics: {
        totalClusters: result.clusters.length,
        criticalCellsInClusters,
        avgClusterImprovement: result.metrics.avgClusterImprovement,
        bestStrategy,
      },
      recommendations: result.recommendations,
    };
  }

  /**
   * Apply feedback from network after deployment
   */
  applyFeedback(
    cellSnapshots: Map<string, CellKPISnapshot>,
    neighborRelations: NeighborRelation[],
    deployedChanges: Array<{
      cellId: string;
      params: PowerControlParams;
      actualSINR: number;
    }>
  ): { avgLoss: number; avgReward: number } {
    const graph = this.graphBuilder.buildGraph(cellSnapshots, neighborRelations);

    let totalLoss = 0;
    let totalReward = 0;

    for (const change of deployedChanges) {
      const { loss, reward } = this.selfLearningGNN.learnFromFeedback(
        graph,
        change.cellId,
        change.params,
        change.actualSINR
      );
      totalLoss += loss;
      totalReward += reward;
    }

    return {
      avgLoss: deployedChanges.length > 0 ? totalLoss / deployedChanges.length : 0,
      avgReward: deployedChanges.length > 0 ? totalReward / deployedChanges.length : 0,
    };
  }

  /**
   * Get model state and metrics
   */
  getStatus(): {
    state: SelfLearningState;
    metrics: LearningMetrics;
    bufferStats: ReturnType<ExperienceReplayBuffer['getStats']>;
  } {
    return {
      state: this.selfLearningGNN.getState(),
      metrics: this.selfLearningGNN.getMetrics(),
      bufferStats: new ExperienceReplayBuffer().getStats(), // Placeholder
    };
  }

  /**
   * Save model checkpoint
   */
  saveCheckpoint(): ReturnType<SelfLearningUplinkGNN['checkpoint']> {
    return this.selfLearningGNN.checkpoint();
  }

  /**
   * Load model checkpoint
   */
  loadCheckpoint(checkpoint: ReturnType<SelfLearningUplinkGNN['checkpoint']>): void {
    this.selfLearningGNN.restore(checkpoint);
  }

  /**
   * Get underlying GNN for advanced operations
   */
  getGNN(): SelfLearningUplinkGNN {
    return this.selfLearningGNN;
  }

  private generateRecommendations(
    results: CellOptimizationResult[],
    issueCells: ReturnType<IssueCellDetector['detectIssueCells']>
  ): string[] {
    const recommendations: string[] = [];
    const state = this.selfLearningGNN.getState();

    if (results.length === 0) {
      recommendations.push('No optimization changes recommended at this time.');
      return recommendations;
    }

    // Model confidence indicator
    recommendations.push(`[Self-Learning GNN v${state.modelVersion}]`);
    recommendations.push(`Model confidence: ${(1 - state.avgLoss).toFixed(2)}`);
    recommendations.push(`Training samples: ${state.totalSamples}`);
    recommendations.push('');

    // Critical cells
    const criticalCells = issueCells.filter(c => c.status === 'critical');
    if (criticalCells.length > 0) {
      recommendations.push(`PRIORITY: ${criticalCells.length} critical cells require immediate attention.`);
    }

    // Sort by improvement
    const sorted = [...results].sort((a, b) => b.sinrImprovement - a.sinrImprovement);
    const topN = Math.min(5, sorted.length);

    recommendations.push(`\nTop ${topN} optimization recommendations:`);

    for (let i = 0; i < topN; i++) {
      const r = sorted[i];
      recommendations.push(
        `  ${i + 1}. ${r.cellId}: P0 ${r.originalParams.p0}${r.optimizedParams.p0} dBm, ` +
        `Alpha ${r.originalParams.alpha}${r.optimizedParams.alpha} ` +
        `(+${r.sinrImprovement.toFixed(1)} dB SINR, confidence: ${(r.confidence * 100).toFixed(0)}%)`
      );
    }

    recommendations.push('\nDeployment notes:');
    recommendations.push('- Apply changes during low-traffic periods');
    recommendations.push('- Model will learn from actual results after deployment');
    recommendations.push('- Re-run optimization after 24-48 hours for continued improvement');

    return recommendations;
  }
}

// ============================================================================
// RUVECTOR CLI INTEGRATION
// ============================================================================

/**
 * Integration with ruvector CLI for model operations
 */
export async function runRuVectorGNNLayer(
  inputDim: number,
  hiddenDim: number,
  heads: number = 4,
  dropout: number = 0.1
): Promise<RuVectorGNNLayer> {
  console.log(`[ruvector] Creating GNN layer: input=${inputDim}, hidden=${hiddenDim}, heads=${heads}`);

  const layer = new RuVectorGNNLayer({
    inputDim,
    hiddenDim,
    numHeads: heads,
    dropout,
  });

  console.log('[ruvector] GNN layer created successfully');
  return layer;
}

/**
 * Run tensor compression on embeddings
 */
export function compressEmbeddings(
  embeddings: number[][],
  level: CompressionLevel = 'auto' as CompressionLevel,
  accessFreq: number = 0.5
): CompressedTensor {
  const flatData = new Float32Array(embeddings.flat());

  let compressionLevel: CompressionLevel;
  if (level === 'auto' as CompressionLevel) {
    if (accessFreq > 0.8) compressionLevel = 'none';
    else if (accessFreq > 0.4) compressionLevel = 'half';
    else if (accessFreq > 0.1) compressionLevel = 'pq8';
    else if (accessFreq > 0.01) compressionLevel = 'pq4';
    else compressionLevel = 'binary';
  } else {
    compressionLevel = level;
  }

  return {
    data: flatData,
    shape: [embeddings.length, embeddings[0]?.length ?? 0],
    compressionLevel,
    accessFrequency: accessFreq,
    lastAccessed: new Date(),
  };
}

/**
 * Run differentiable search
 */
export function differentiableSearch(
  query: number[],
  candidates: number[][],
  topK: number = 5,
  temperature: number = 1.0
): { indices: number[]; scores: number[]; softWeights: number[] } {
  // Compute similarities
  const similarities = candidates.map(candidate => {
    let sim = 0;
    for (let i = 0; i < query.length && i < candidate.length; i++) {
      sim += query[i] * candidate[i];
    }
    return sim;
  });

  // Softmax with temperature
  const maxSim = Math.max(...similarities);
  const expSims = similarities.map(s => Math.exp((s - maxSim) / temperature));
  const sumExp = expSims.reduce((a, b) => a + b, 1e-9);
  const softWeights = expSims.map(s => s / sumExp);

  // Get top-K indices
  const indexedSims = similarities.map((s, i) => ({ index: i, score: s }));
  indexedSims.sort((a, b) => b.score - a.score);
  const topIndices = indexedSims.slice(0, topK).map(x => x.index);
  const topScores = indexedSims.slice(0, topK).map(x => x.score);

  return {
    indices: topIndices,
    scores: topScores,
    softWeights,
  };
}

// ============================================================================
// EXPORTS
// ============================================================================

export default {
  // Core classes
  RuVectorGNNLayer,
  ExperienceReplayBuffer,
  DifferentiableParameterSearch,
  InterferenceAwareCandidateGenerator,
  SelfLearningUplinkGNN,
  EricssonUplinkOptimizer,

  // CLI integration
  runRuVectorGNNLayer,
  compressEmbeddings,
  differentiableSearch,
};
