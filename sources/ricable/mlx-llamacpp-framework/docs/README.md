# Running LLMs on Apple Silicon

Welcome to the complete documentation for running Large Language Models on Apple Silicon. This documentation covers everything you need to run, quantize, and fine-tune LLMs locally on your Mac using the llama.cpp and MLX frameworks.

## Documentation Structure

- **Core Documentation**
  - [Getting Started](getting-started.md) - Installation and basic setup
  - [Project Overview](project-overview.md) - Architecture and component explanation

- **Framework Guides**
  - [llama.cpp Guide](frameworks/llama-cpp-guide.md) - Complete guide to llama.cpp
  - [MLX Guide](frameworks/mlx-guide.md) - Complete guide to Apple's MLX framework
  - [Framework Comparison](frameworks/framework-comparison.md) - Choosing the right framework

- **Use Case Guides**
  - [Inference Guide](use-cases/inference-guide.md) - Running models for text generation
  - [Chat Applications](use-cases/chat-applications.md) - Building interactive chat interfaces
  - [Fine-tuning Guide](use-cases/fine-tuning-guide.md) - Personalizing models with your data

- **Hardware and Performance**
  - [Hardware Recommendations](hardware/hardware-recommendations.md) - Choosing the right Mac
  - [Memory Management](hardware/memory-management.md) - Working within RAM constraints
  - [Performance Optimization](hardware/performance-optimization.md) - Getting the best performance

- **Advanced Topics**
  - [Quantization Guide](advanced/quantization-guide.md) - Reducing model size and memory usage
  - [Integration with Applications](advanced/application-integration.md) - Embedding LLMs in apps
  - [Multi-modal Models](advanced/multi-modal-models.md) - Working with text+vision models

## Quick Start

If you're new to running LLMs on Apple Silicon, we recommend starting with:

1. [Getting Started](getting-started.md) - Set up your environment
2. [Inference Guide](use-cases/inference-guide.md) - Run your first model
3. [Framework Comparison](frameworks/framework-comparison.md) - Choose the right framework for your needs

## Contributing to Documentation

We welcome contributions to improve this documentation. Please feel free to submit pull requests with corrections, clarifications, or new content.

## License

This documentation is licensed under the MIT License - see the LICENSE file for details.