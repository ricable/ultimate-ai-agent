#!/bin/bash

# Comprehensive test runner for Synaptic Neural Mesh
# Runs all test suites with coverage and reporting

set -e

echo "üß™ Synaptic Neural Mesh - Comprehensive Test Suite"
echo "================================================="

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
TEST_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$TEST_DIR")"
COVERAGE_DIR="$TEST_DIR/coverage"
REPORTS_DIR="$TEST_DIR/reports"
LOG_FILE="$REPORTS_DIR/test-execution.log"

# Create directories
mkdir -p "$COVERAGE_DIR" "$REPORTS_DIR"

# Start logging
exec 1> >(tee -a "$LOG_FILE")
exec 2> >(tee -a "$LOG_FILE" >&2)

echo "Test execution started at: $(date)"
echo "Project root: $PROJECT_ROOT"
echo "Test directory: $TEST_DIR"
echo ""

# Test execution functions
run_rust_tests() {
    echo -e "${BLUE}ü¶Ä Running Rust Unit Tests...${NC}"
    
    cd "$PROJECT_ROOT/src/rs"
    
    # QuDAG tests
    echo "  Testing QuDAG..."
    cd QuDAG/QuDAG-main
    if cargo test --workspace --verbose; then
        echo -e "  ${GREEN}‚úÖ QuDAG tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå QuDAG tests failed${NC}"
        return 1
    fi
    
    cd ../..
    
    # ruv-FANN tests
    echo "  Testing ruv-FANN..."
    cd ruv-FANN
    if cargo test --features test-core --verbose; then
        echo -e "  ${GREEN}‚úÖ ruv-FANN tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå ruv-FANN tests failed${NC}"
        return 1
    fi
    
    cd ..
    
    # DAA tests
    echo "  Testing DAA..."
    cd daa/daa-main
    if cargo test --verbose; then
        echo -e "  ${GREEN}‚úÖ DAA tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå DAA tests failed${NC}"
        return 1
    fi
    
    cd "$PROJECT_ROOT"
    echo -e "${GREEN}ü¶Ä All Rust tests completed successfully${NC}"
}

run_javascript_tests() {
    echo -e "${BLUE}üü® Running JavaScript/TypeScript Tests...${NC}"
    
    # Claude Flow tests
    echo "  Testing Claude Flow..."
    cd "$PROJECT_ROOT/src/js/claude-flow"
    if npm test; then
        echo -e "  ${GREEN}‚úÖ Claude Flow tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå Claude Flow tests failed${NC}"
        return 1
    fi
    
    # ruv-swarm tests
    echo "  Testing ruv-swarm..."
    cd "../ruv-swarm"
    if npm run test:all; then
        echo -e "  ${GREEN}‚úÖ ruv-swarm tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå ruv-swarm tests failed${NC}"
        return 1
    fi
    
    cd "$PROJECT_ROOT"
    echo -e "${GREEN}üü® All JavaScript tests completed successfully${NC}"
}

run_unit_tests() {
    echo -e "${BLUE}üî¨ Running Unit Tests...${NC}"
    
    cd "$TEST_DIR/unit"
    
    # Install dependencies if needed
    if [ ! -d "node_modules" ]; then
        echo "  Installing test dependencies..."
        npm install
    fi
    
    # Run JavaScript unit tests
    if npm run test:js; then
        echo -e "  ${GREEN}‚úÖ JavaScript unit tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå JavaScript unit tests failed${NC}"
        return 1
    fi
    
    # Run Rust unit tests
    if npm run test:rust; then
        echo -e "  ${GREEN}‚úÖ Rust unit tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå Rust unit tests failed${NC}"
        return 1
    fi
    
    cd "$PROJECT_ROOT"
    echo -e "${GREEN}üî¨ Unit tests completed successfully${NC}"
}

run_integration_tests() {
    echo -e "${BLUE}üîó Running Integration Tests...${NC}"
    
    cd "$TEST_DIR/integration"
    
    # WASM integration tests
    echo "  Testing WASM integration..."
    if node wasm-integration.test.js; then
        echo -e "  ${GREEN}‚úÖ WASM integration tests passed${NC}"
    else
        echo -e "  ${RED}‚ùå WASM integration tests failed${NC}"
        return 1
    fi
    
    cd "$PROJECT_ROOT"
    echo -e "${GREEN}üîó Integration tests completed successfully${NC}"
}

run_performance_tests() {
    echo -e "${BLUE}‚ö° Running Performance Tests...${NC}"
    
    cd "$TEST_DIR/performance"
    
    echo "  Running performance benchmarks..."
    if node benchmark-suite.js > "$REPORTS_DIR/performance-report.json"; then
        echo -e "  ${GREEN}‚úÖ Performance tests completed${NC}"
        echo "  üìä Performance report saved to $REPORTS_DIR/performance-report.json"
    else
        echo -e "  ${YELLOW}‚ö†Ô∏è Some performance targets not met${NC}"
    fi
    
    cd "$PROJECT_ROOT"
}

run_stress_tests() {
    echo -e "${BLUE}üî• Running Stress Tests...${NC}"
    
    cd "$TEST_DIR/stress"
    
    echo "  Running stress test suite..."
    if timeout 300 node stress-test-suite.js > "$REPORTS_DIR/stress-report.json"; then
        echo -e "  ${GREEN}‚úÖ Stress tests completed${NC}"
        echo "  üìä Stress test report saved to $REPORTS_DIR/stress-report.json"
    else
        echo -e "  ${YELLOW}‚ö†Ô∏è Stress tests timed out or failed${NC}"
    fi
    
    cd "$PROJECT_ROOT"
}

run_coverage_analysis() {
    echo -e "${BLUE}üìä Running Coverage Analysis...${NC}"
    
    # JavaScript coverage
    echo "  Collecting JavaScript coverage..."
    cd "$PROJECT_ROOT/src/js/claude-flow"
    npm run test:coverage > "$COVERAGE_DIR/js-coverage.txt" 2>&1 || true
    
    cd "../ruv-swarm"
    npm run test:coverage > "$COVERAGE_DIR/ruv-swarm-coverage.txt" 2>&1 || true
    
    # Rust coverage (if tarpaulin is available)
    echo "  Collecting Rust coverage..."
    cd "$PROJECT_ROOT/src/rs"
    
    # Try to run coverage for each Rust project
    for project in QuDAG/QuDAG-main ruv-FANN daa/daa-main; do
        if [ -d "$project" ]; then
            cd "$project"
            if command -v cargo-tarpaulin >/dev/null 2>&1; then
                cargo tarpaulin --out Html --output-dir "$COVERAGE_DIR" --timeout 300 || true
            else
                echo "    cargo-tarpaulin not available, skipping Rust coverage for $project"
            fi
            cd - >/dev/null
        fi
    done
    
    cd "$PROJECT_ROOT"
    echo -e "${GREEN}üìä Coverage analysis completed${NC}"
}

generate_summary_report() {
    echo -e "${BLUE}üìã Generating Test Summary Report...${NC}"
    
    SUMMARY_FILE="$REPORTS_DIR/test-summary-$(date +%Y%m%d-%H%M%S).md"
    
    cat > "$SUMMARY_FILE" << EOF
# Synaptic Neural Mesh Test Execution Summary

**Execution Date:** $(date)
**Project Root:** $PROJECT_ROOT
**Test Duration:** $((SECONDS / 60)) minutes $((SECONDS % 60)) seconds

## Test Results Overview

| Test Category | Status | Details |
|---------------|--------|---------|
| Rust Unit Tests | $RUST_STATUS | QuDAG, ruv-FANN, DAA modules |
| JavaScript Tests | $JS_STATUS | Claude Flow, ruv-swarm |
| Unit Tests | $UNIT_STATUS | Comprehensive unit test suite |
| Integration Tests | $INTEGRATION_STATUS | WASM and cross-component tests |
| Performance Tests | ‚ö° Completed | See performance-report.json |
| Stress Tests | üî• Completed | See stress-report.json |
| Coverage Analysis | üìä Completed | Coverage reports in coverage/ |

## Test Coverage Summary

### JavaScript Coverage
- **Claude Flow:** See js-coverage.txt
- **ruv-swarm:** See ruv-swarm-coverage.txt

### Rust Coverage
- **QuDAG:** Tarpaulin coverage reports
- **ruv-FANN:** Unit test coverage
- **DAA:** Component coverage

## Performance Metrics

Performance benchmark results are available in the performance-report.json file.
Key metrics tested:
- Neural inference time (<100ms target)
- Memory usage per agent (<50MB target)
- Concurrent agent handling (1000+ agents target)
- Swarm coordination time (<1s target)
- SWE-Bench solve rate (>84.8% target)

## Stress Test Results

Stress test results are available in the stress-report.json file.
Categories tested:
- High load handling (10,000+ ops/sec)
- Fault tolerance and recovery
- Memory leak detection
- Edge case handling
- Extended stability (24-hour simulation)

## Recommendations

### Passing Tests
- Continue maintaining current test coverage
- Monitor performance regression

### Failing Tests
- Review failed test logs in test-execution.log
- Address any performance bottlenecks
- Fix failing unit or integration tests

## Files Generated

- \`test-execution.log\` - Complete test execution log
- \`performance-report.json\` - Performance benchmark results
- \`stress-report.json\` - Stress test results
- \`coverage/\` - Code coverage reports
- \`test-summary-*.md\` - This summary report

## Next Steps

1. Review any failing tests
2. Address performance issues if any
3. Update test suites as system evolves
4. Consider adding more edge cases
5. Implement automated CI/CD integration

---
*Generated by Synaptic Neural Mesh Test Suite*
EOF

    echo "üìã Test summary report generated: $SUMMARY_FILE"
}

# Main execution flow
main() {
    local start_time=$(date +%s)
    
    echo "Starting comprehensive test execution..."
    echo ""
    
    # Initialize status variables
    RUST_STATUS="‚ùå Failed"
    JS_STATUS="‚ùå Failed"
    UNIT_STATUS="‚ùå Failed"
    INTEGRATION_STATUS="‚ùå Failed"
    
    # Run test suites
    if run_rust_tests; then
        RUST_STATUS="‚úÖ Passed"
    fi
    
    if run_javascript_tests; then
        JS_STATUS="‚úÖ Passed"
    fi
    
    if run_unit_tests; then
        UNIT_STATUS="‚úÖ Passed"
    fi
    
    if run_integration_tests; then
        INTEGRATION_STATUS="‚úÖ Passed"
    fi
    
    # Always run performance and stress tests (non-failing)
    run_performance_tests
    run_stress_tests
    run_coverage_analysis
    
    # Generate final report
    local end_time=$(date +%s)
    SECONDS=$((end_time - start_time))
    
    generate_summary_report
    
    echo ""
    echo "üéâ Test execution completed!"
    echo "‚è±Ô∏è  Total time: $((SECONDS / 60))m $((SECONDS % 60))s"
    echo "üìÅ Reports available in: $REPORTS_DIR"
    echo "üìÑ Summary report: $SUMMARY_FILE"
    
    # Determine overall success
    if [[ "$RUST_STATUS" == *"Passed"* ]] && 
       [[ "$JS_STATUS" == *"Passed"* ]] && 
       [[ "$UNIT_STATUS" == *"Passed"* ]] && 
       [[ "$INTEGRATION_STATUS" == *"Passed"* ]]; then
        echo -e "${GREEN}‚úÖ All critical tests passed!${NC}"
        exit 0
    else
        echo -e "${RED}‚ùå Some critical tests failed. Check the reports.${NC}"
        exit 1
    fi
}

# Handle script arguments
case "${1:-}" in
    --help|-h)
        echo "Usage: $0 [OPTIONS]"
        echo ""
        echo "Options:"
        echo "  --help, -h     Show this help message"
        echo "  --unit-only    Run only unit tests"
        echo "  --perf-only    Run only performance tests"
        echo "  --stress-only  Run only stress tests"
        echo "  --no-coverage  Skip coverage analysis"
        echo ""
        echo "Examples:"
        echo "  $0                 # Run all tests"
        echo "  $0 --unit-only    # Run only unit tests"
        echo "  $0 --perf-only    # Run only performance tests"
        exit 0
        ;;
    --unit-only)
        echo "üî¨ Running unit tests only..."
        run_unit_tests && echo "‚úÖ Unit tests completed" || echo "‚ùå Unit tests failed"
        exit $?
        ;;
    --perf-only)
        echo "‚ö° Running performance tests only..."
        run_performance_tests
        exit 0
        ;;
    --stress-only)
        echo "üî• Running stress tests only..."
        run_stress_tests
        exit 0
        ;;
    --no-coverage)
        echo "Running tests without coverage analysis..."
        # Set flag to skip coverage
        SKIP_COVERAGE=1
        ;;
esac

# Run main execution
main "$@"