# =============================================================================
# LiteLLM AI Gateway Configuration
# Edge-Native AI - Local-First with Cloud Fallback
# =============================================================================

model_list:
  # ===========================================================================
  # LOCAL MODELS (Priority 1 - Zero Cost)
  # ===========================================================================

  # Qwen 2.5 Coder - Primary local coding model
  - model_name: qwen-coder
    litellm_params:
      model: openai/qwen2.5-coder-7b
      api_base: http://localai.edge-ai-inference:8080/v1
      api_key: "sk-not-needed"
      max_tokens: 8192
      temperature: 0.7
    model_info:
      id: qwen-coder-7b-local
      mode: chat
      tier: local
      input_cost_per_token: 0
      output_cost_per_token: 0
      supports_function_calling: true

  - model_name: qwen-coder-14b
    litellm_params:
      model: openai/qwen2.5-coder-14b
      api_base: http://localai.edge-ai-inference:8080/v1
      api_key: "sk-not-needed"
      max_tokens: 16384
    model_info:
      tier: local
      input_cost_per_token: 0
      output_cost_per_token: 0

  # Local general-purpose model
  - model_name: local-general
    litellm_params:
      model: openai/llama-3.2-3b
      api_base: http://localai.edge-ai-inference:8080/v1
      api_key: "sk-not-needed"
    model_info:
      tier: local
      input_cost_per_token: 0
      output_cost_per_token: 0

  # Local embedding model
  - model_name: local-embedding
    litellm_params:
      model: openai/text-embedding-ada-002
      api_base: http://localai.edge-ai-inference:8080/v1
      api_key: "sk-not-needed"
    model_info:
      tier: local
      mode: embedding

  # ===========================================================================
  # GAIANET MODELS (Priority 2 - Decentralized)
  # ===========================================================================

  - model_name: gaianet-coder
    litellm_params:
      model: openai/Qwen2.5-Coder-32B-Instruct
      api_base: https://coder.gaianet.network/v1
      api_key: "gaia-not-needed"
    model_info:
      tier: decentralized
      input_cost_per_token: 0.0001
      output_cost_per_token: 0.0002

  # ===========================================================================
  # CLOUD MODELS (Priority 3 - Fallback for Complex Tasks)
  # ===========================================================================

  # OpenAI GPT-4o
  - model_name: gpt-4o
    litellm_params:
      model: gpt-4o
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tier: cloud
      input_cost_per_token: 0.0025
      output_cost_per_token: 0.01

  - model_name: gpt-4o-mini
    litellm_params:
      model: gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tier: cloud
      input_cost_per_token: 0.00015
      output_cost_per_token: 0.0006

  # Anthropic Claude
  - model_name: claude-3.5-sonnet
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tier: cloud
      input_cost_per_token: 0.003
      output_cost_per_token: 0.015

  - model_name: claude-3-haiku
    litellm_params:
      model: claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      tier: cloud
      input_cost_per_token: 0.00025
      output_cost_per_token: 0.00125

  # OpenAI Embeddings (fallback)
  - model_name: text-embedding-ada-002
    litellm_params:
      model: text-embedding-ada-002
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      tier: cloud
      mode: embedding

# =============================================================================
# ROUTER SETTINGS
# =============================================================================

router_settings:
  # Cost-based routing - prefer cheaper (local) models
  routing_strategy: "cost-based-routing"

  # Model group aliases
  model_group_alias:
    # Default coding model routes to local first
    coder: ["qwen-coder", "qwen-coder-14b", "gaianet-coder", "gpt-4o"]
    # Fast model for simple tasks
    fast: ["local-general", "gpt-4o-mini", "claude-3-haiku"]
    # Best model for complex reasoning
    best: ["gpt-4o", "claude-3.5-sonnet", "qwen-coder-14b"]
    # Embedding model
    embedding: ["local-embedding", "text-embedding-ada-002"]

  # Fallback configuration
  fallbacks:
    qwen-coder: ["qwen-coder-14b", "gaianet-coder", "gpt-4o"]
    local-general: ["gpt-4o-mini", "claude-3-haiku"]
    local-embedding: ["text-embedding-ada-002"]

  # Retry settings
  num_retries: 3
  timeout: 120
  retry_after: 5

  # Caching
  cache: true
  cache_params:
    type: "redis"
    host: "redis.edge-ai-data"
    port: 6379
    ttl: 3600

  # Rate limiting
  redis_host: "redis.edge-ai-data"
  redis_port: 6379

# =============================================================================
# GENERAL SETTINGS
# =============================================================================

general_settings:
  # Master API key (set via environment)
  master_key: os.environ/LITELLM_MASTER_KEY

  # Database for tracking
  database_url: os.environ/DATABASE_URL

  # Enable detailed logging
  set_verbose: false

  # Maximum parallel requests
  max_parallel_requests: 100

  # Budget settings
  max_budget: 1000.0
  budget_duration: "monthly"

  # Alerting
  alerting:
    - webhook

  alerting_args:
    webhook_url: os.environ/ALERT_WEBHOOK_URL

# =============================================================================
# LITELLM SETTINGS
# =============================================================================

litellm_settings:
  # Request settings
  request_timeout: 120
  stream_timeout: 300

  # Enable streaming
  stream: true

  # Enable function calling
  drop_params: false

  # Callbacks
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]

  # Langfuse integration
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST

  # Custom headers
  default_headers:
    x-edge-ai-version: "1.0.0"
    x-routing-strategy: "local-first"

# =============================================================================
# ENVIRONMENT CONFIGURATION
# =============================================================================

environment_variables:
  # Local inference
  LOCALAI_API_BASE: "http://localai.edge-ai-inference:8080/v1"

  # GaiaNet
  GAIANET_API_BASE: "https://coder.gaianet.network/v1"

  # Redis
  REDIS_URL: "redis://redis.edge-ai-data:6379"

  # PostgreSQL
  DATABASE_URL: "postgresql://edgeai:password@postgres.edge-ai-data:5432/litellm"
