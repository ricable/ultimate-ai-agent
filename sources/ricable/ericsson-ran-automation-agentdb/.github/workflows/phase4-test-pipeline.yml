name: Phase 4 Test Pipeline
description: Comprehensive test suite with unit, integration, E2E, and performance validation

on:
  push:
    branches: [main, develop, feat/phase4]
  pull_request:
    branches: [main, develop]
  workflow_call:
    inputs:
      build_version:
        description: 'Build version to test'
        required: true
        type: string
      test_level:
        description: 'Test level to run'
        required: true
        default: 'all'
        type: choice
        options:
        - smoke
        - regression
        - full
        - performance
      environment:
        description: 'Target environment'
        required: false
        default: 'staging'
        type: string
  schedule:
    # Run comprehensive tests nightly at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'all'
        type: choice
        options:
        - unit
        - integration
        - e2e
        - performance
        - security
        - all
      parallel_execution:
        description: 'Run tests in parallel'
        required: false
        default: true
        type: boolean
      generate_report:
        description: 'Generate detailed test report'
        required: false
        default: true
        type: boolean

env:
  NODE_VERSION: '18'
  TEST_TIMEOUT: 300000
  COVERAGE_THRESHOLD: 80
  PERFORMANCE_THRESHOLD: 95
  REPORT_RETENTION_DAYS: 30

jobs:
  # Test matrix configuration
  test-matrix:
    name: Test Matrix Configuration
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.matrix.outputs.json }}
      parallel-execution: ${{ steps.matrix.outputs.parallel }}
    steps:
      - name: Configure test matrix
        id: matrix
        run: |
          MATRIX_CONFIG='{
            "unit": {
              "node-version": [18, 20],
              "os": ["ubuntu-latest", "windows-latest"],
              "shard": [1, 2, 3]
            },
            "integration": {
              "services": ["redis", "mongodb", "postgresql"],
              "test-types": ["api", "database", "ml", "agentdb"]
            },
            "e2e": {
              "browsers": ["chrome", "firefox"],
              "environments": ["staging", "production"]
            },
            "performance": {
              "load-levels": ["light", "medium", "heavy"],
              "duration": ["5m", "15m", "30m"]
            }
          }'

          PARALLEL="${{ github.event.inputs.parallel_execution || 'true' }}"
          echo "json=$MATRIX_CONFIG" >> $GITHUB_OUTPUT
          echo "parallel=$PARALLEL" >> $GITHUB_OUTPUT

  # Environment setup for tests
  test-setup:
    name: Test Environment Setup
    runs-on: ubuntu-latest
    needs: test-matrix
    outputs:
      test-environment: ${{ steps.setup.outputs.environment }}
      test-data-ready: ${{ steps.setup.outputs.data-ready }}
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      mongodb:
        image: mongo:6
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.runCommand(\"ping\")'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      postgres:
        image: postgres:15
        ports:
          - 5432:5432
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Setup test environment
        id: setup
        run: |
          # Create test environment files
          cat > .env.test << EOF
          NODE_ENV=test
          REDIS_URL=redis://localhost:6379
          MONGODB_URL=mongodb://localhost:27017/test_db
          POSTGRES_URL=postgresql://postgres:postgres@localhost:5432/test_db
          LOG_LEVEL=debug
          TEST_TIMEOUT=${{ env.TEST_TIMEOUT }}
          EOF

          # Seed test data
          npm run test:seed-data || echo "Seed data script not found"

          # Validate test environment
          node -e "
            console.log('ðŸ§ª Test Environment Setup Complete');
            console.log('Redis:', process.env.REDIS_URL);
            console.log('MongoDB:', process.env.MONGODB_URL);
            console.log('PostgreSQL:', process.env.POSTGRES_URL);
          "

          echo "environment=test" >> $GITHUB_OUTPUT
          echo "data-ready=true" >> $GITHUB_OUTPUT

  # Unit Tests with comprehensive coverage
  unit-tests:
    name: Unit Tests - Node ${{ matrix.node-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    needs: [test-matrix, test-setup]
    if: always() && needs.test-setup.outputs.test-data-ready == 'true'
    strategy:
      fail-fast: false
      matrix:
        include:
          - node-version: 18
            os: ubuntu-latest
            shard: 1
          - node-version: 18
            os: ubuntu-latest
            shard: 2
          - node-version: 18
            os: ubuntu-latest
            shard: 3
          - node-version: 20
            os: ubuntu-latest
            shard: 1
          - node-version: 20
            os: windows-latest
            shard: 1
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Run unit tests with sharding
        run: |
          TOTAL_SHARDS=3
          CURRENT_SHARD=${{ matrix.shard }}

          npm run test:unit -- --shard=$CURRENT_SHARD/$TOTAL_SHARDS \
            --coverage \
            --coverage-threshold=${{ env.COVERAGE_THRESHOLD }} \
            --test-timeout=${{ env.TEST_TIMEOUT }} \
            --reporters=default,junit \
            --outputFile=test-results/junit-unit-${{ matrix.node-version }}-${{ matrix.shard }}.xml

      - name: Run ML-specific unit tests
        run: npm run test:ml

      - name: Run AgentDB unit tests
        run: npm run test:agentdb

      - name: Run Stream Chain unit tests
        run: npm run test:stream-chain

      - name: Generate coverage report
        run: |
          npm run test:coverage -- --coverage-reporters=json,html,lcov,text-summary
          COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')
          echo "Coverage: $COVERAGE%"

          if (( $(echo "$COVERAGE < ${{ env.COVERAGE_THRESHOLD }}" | bc -l) )); then
            echo "âŒ Coverage below threshold (${{ env.COVERAGE_THRESHOLD }}%)"
            exit 1
          fi

      - name: Upload unit test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: unit-test-results-node${{ matrix.node-version }}-shard${{ matrix.shard }}
          path: |
            coverage/
            test-results/
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

  # Integration Tests with real services
  integration-tests:
    name: Integration Tests - ${{ matrix.test-type }}
    runs-on: ubuntu-latest
    needs: [test-matrix, test-setup]
    if: always() && needs.test-setup.outputs.test-data-ready == 'true'
    strategy:
      fail-fast: false
      matrix:
        test-type: [api, database, ml, agentdb, cognitive, temporal]
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
      mongodb:
        image: mongo:6
        ports:
          - 27017:27017
      postgres:
        image: postgres:15
        ports:
          - 5432:5432
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Download build artifacts
        if: github.event_name == 'workflow_call'
        uses: actions/download-artifact@v3
        with:
          name: build-${{ github.event.inputs.build_version }}
          path: dist/

      - name: Run integration tests - ${{ matrix.test-type }}
        run: |
          case "${{ matrix.test-type }}" in
            "api")
              npm run test:integration:api -- --timeout=${{ env.TEST_TIMEOUT }}
              ;;
            "database")
              npm run test:integration:database -- --timeout=${{ env.TEST_TIMEOUT }}
              ;;
            "ml")
              npm run test:ml:integration -- --timeout=${{ env.TEST_TIMEOUT }}
              ;;
            "agentdb")
              npm run test:agentdb:integration -- --timeout=${{ env.TEST_TIMEOUT }}
              ;;
            "cognitive")
              npm run test:cognitive:integration -- --timeout=${{ env.TEST_TIMEOUT }}
              ;;
            "temporal")
              npm run test:temporal:integration -- --timeout=${{ env.TEST_TIMEOUT }}
              ;;
          esac
        env:
          NODE_ENV: test
          REDIS_URL: redis://localhost:6379
          MONGODB_URL: mongodb://localhost:27017/test_db
          POSTGRES_URL: postgresql://postgres:postgres@localhost:5432/test_db

      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results-${{ matrix.test-type }}
          path: |
            integration-test-results/
            test-results/
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

  # End-to-End Tests
  e2e-tests:
    name: E2E Tests - ${{ matrix.browser }} on ${{ matrix.environment }}
    runs-on: ubuntu-latest
    needs: [test-matrix, test-setup]
    if: always() && needs.test-setup.outputs.test-data-ready == 'true'
    strategy:
      fail-fast: false
      matrix:
        browser: [chrome, firefox]
        environment: [staging]
        include:
          - browser: chrome
            environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Setup Playwright
        uses: actions/setup-playwright@v1
        with:
          browser-version: ${{ matrix.browser }}

      - name: Install Playwright browsers
        run: npx playwright install ${{ matrix.browser }}

      - name: Download build artifacts
        if: github.event_name == 'workflow_call'
        uses: actions/download-artifact@v3
        with:
          name: build-${{ github.event.inputs.build_version }}
          path: dist/

      - name: Start application
        run: |
          npm start &
          sleep 10
          curl -f http://localhost:8080/health || exit 1

      - name: Run E2E tests
        run: |
          npm run test:e2e -- --project=${{ matrix.browser }} \
            --grep="${{ matrix.environment }}" \
            --timeout=${{ env.TEST_TIMEOUT }} \
            --reporter=html,json
        env:
          BASE_URL: http://localhost:8080
          BROWSER: ${{ matrix.browser }}
          ENVIRONMENT: ${{ matrix.environment }}

      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results-${{ matrix.browser }}-${{ matrix.environment }}
          path: |
            playwright-report/
            test-results/
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

  # Performance Tests
  performance-tests:
    name: Performance Tests - ${{ matrix.load-level }} Load
    runs-on: ubuntu-latest
    needs: [test-matrix, test-setup]
    if: always() && needs.test-setup.outputs.test-data-ready == 'true'
    strategy:
      fail-fast: false
      matrix:
        load-level: [light, medium, heavy]
        include:
          - load-level: light
            duration: 5m
            vus: 10
          - load-level: medium
            duration: 15m
            vus: 50
          - load-level: heavy
            duration: 30m
            vus: 200
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Download build artifacts
        if: github.event_name == 'workflow_call'
        uses: actions/download-artifact@v3
        with:
          name: build-${{ github.event.inputs.build_version }}
          path: dist/

      - name: Start application
        run: |
          npm start &
          sleep 30
          curl -f http://localhost:8080/health || exit 1

      - name: Run performance tests
        run: |
          k6 run --vus ${{ matrix.vus }} \
            --duration ${{ matrix.duration }} \
            --out json=performance-results-${{ matrix.load-level }}.json \
            tests/performance/load-test.js

      - name: Run cognitive performance tests
        run: |
          npm run test:performance:cognitive -- --duration=${{ matrix.duration }}

      - name: Validate performance thresholds
        run: |
          # Analyze performance results and validate against thresholds
          node -e "
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('performance-results-${{ matrix.load-level }}.json', 'utf8'));

            const avgResponseTime = results.metrics.http_req_duration.values.avg;
            const errorRate = results.metrics.http_req_failed.rate;
            const throughput = results.metrics.http_reqs.rate;

            console.log('ðŸŽ¯ Performance Test Results - ${{ matrix.load-level }}');
            console.log('Response Time:', avgResponseTime.toFixed(2), 'ms');
            console.log('Error Rate:', (errorRate * 100).toFixed(2), '%');
            console.log('Throughput:', throughput.toFixed(0), 'req/s');

            // Performance thresholds
            const RESPONSE_TIME_THRESHOLD = 5000; // 5s
            const ERROR_RATE_THRESHOLD = 0.01; // 1%

            if (avgResponseTime > RESPONSE_TIME_THRESHOLD) {
              console.log('âŒ Response time exceeds threshold');
              process.exit(1);
            }

            if (errorRate > ERROR_RATE_THRESHOLD) {
              console.log('âŒ Error rate exceeds threshold');
              process.exit(1);
            }

            console.log('âœ… Performance validation passed');
          "

      - name: Upload performance test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results-${{ matrix.load-level }}
          path: |
            performance-results-*.json
            performance-reports/
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

  # Security Tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: [test-matrix, test-setup]
    if: always() && needs.test-setup.outputs.test-data-ready == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Run OWASP ZAP Baseline Scan
        run: |
          npm start &
          sleep 30

          docker run -t owasp/zap2docker-stable \
            zap-baseline.py -t http://localhost:8080 \
            -J zap-report.json || true

      - name: Run security integration tests
        run: npm run test:security:integration

      - name: Run penetration tests
        run: npm run test:security:penetration

      - name: Upload security test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-results
          path: |
            zap-report.json
            security-test-results/
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

  # Test Report Generation
  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, security-tests]
    if: always()
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v3
        with:
          path: all-test-results/

      - name: Generate comprehensive test report
        run: |
          npm run test:report:generate -- \
            --input-dir=all-test-results \
            --output-dir=test-report \
            --format=html,json,markdown

      - name: Upload comprehensive test report
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-test-report
          path: test-report/
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');

            try {
              const report = JSON.parse(fs.readFileSync('test-report/summary.json', 'utf8'));

              const comment = `
              ## ðŸ§ª Test Pipeline Results

              **Overall Status:** ${report.status === 'passed' ? 'âœ… PASSED' : 'âŒ FAILED'}

              ### Test Suite Results:
              - **Unit Tests:** ${report.results.unitTests.status} (${report.results.unitTests.passed}/${report.results.unitTests.total})
              - **Integration Tests:** ${report.results.integrationTests.status} (${report.results.integrationTests.passed}/${report.results.integrationTests.total})
              - **E2E Tests:** ${report.results.e2eTests.status} (${report.results.e2eTests.passed}/${report.results.e2eTests.total})
              - **Performance Tests:** ${report.results.performanceTests.status}
              - **Security Tests:** ${report.results.securityTests.status}

              **Coverage:** ${report.coverage.percentage}%
              **Duration:** ${report.duration}s

              [View Detailed Report](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.log('Could not generate test report comment:', error.message);
            }

  # Test Pipeline Summary
  test-summary:
    name: Test Pipeline Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, security-tests, test-report]
    if: always()
    steps:
      - name: Test Pipeline Summary
        run: |
          echo "## ðŸ§ª Phase 4 Test Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Level:** ${{ github.event.inputs.test_level || 'all' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ github.event.inputs.environment || 'staging' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Execution Mode:** ${{ github.event.inputs.parallel_execution || 'true' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### ðŸ“Š Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result }} | Multi-node, multi-OS coverage |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result }} | Real services integration |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ needs.e2e-tests.result }} | Browser automation |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Tests | ${{ needs.performance-tests.result }} | Load testing with k6 |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Tests | ${{ needs.security-tests.result }} | OWASP ZAP, penetration |" >> $GITHUB_STEP_SUMMARY
          echo "| Test Report | ${{ needs.test-report.result }} | Comprehensive analysis |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ "${{ needs.unit-tests.result }}" == "success" && "${{ needs.integration-tests.result }}" == "success" ]]; then
            echo "âœ… **Test pipeline completed successfully! Ready for deployment.**" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Test pipeline has failures. Please review the failed test suites.**" >> $GITHUB_STEP_SUMMARY
          fi

  # Cleanup
  cleanup:
    name: Cleanup Test Resources
    runs-on: ubuntu-latest
    needs: [test-summary]
    if: always()
    steps:
      - name: Cleanup test data
        run: |
          echo "ðŸ§¹ Cleaning up test resources..."
          # Add any specific cleanup commands here
          echo "Test resources cleaned up successfully"