/**
 * Federated Learning with Quantum-Resistant Security
 *
 * This example demonstrates distributed machine learning using the Prime framework
 * with quantum-resistant cryptography for secure gradient sharing and model updates.
 *
 * Features:
 * - Distributed training nodes
 * - Secure gradient aggregation with ML-KEM
 * - Byzantine fault tolerance
 * - Model versioning with BLAKE3 hashing
 * - Token-based incentive mechanism
 *
 * @example
 * ```bash
 * npm install @daa/qudag-native daa-prime-core daa-prime-trainer
 * ts-node examples/federated-learning.ts
 * ```
 */

import { MlKem768, blake3Hash, quantumFingerprint } from '@daa/qudag-native';

/**
 * Training Node Identity
 */
interface NodeIdentity {
  id: string;
  publicKey: Buffer;
  secretKey: Buffer;
  fingerprint: string;
  reputation: number;
}

/**
 * Model Gradient
 */
interface Gradient {
  layerId: string;
  weights: number[];
  timestamp: number;
  nodeId: string;
  signature?: Buffer;
}

/**
 * Training Round
 */
interface TrainingRound {
  roundNumber: number;
  modelVersion: string;
  participants: string[];
  aggregatedGradient?: Gradient[];
  byzantineNodesDetected: string[];
}

/**
 * Create a training node identity with quantum-resistant keys
 */
async function createNodeIdentity(id: string): Promise<NodeIdentity> {
  console.log(`\nğŸ–¥ï¸  Creating training node: ${id}`);

  const mlkem = new MlKem768();
  const keypair = mlkem.generateKeypair();

  const identityData = Buffer.from(JSON.stringify({
    id,
    publicKey: keypair.publicKey.toString('hex'),
    timestamp: Date.now()
  }));

  const fingerprint = quantumFingerprint(identityData);

  console.log(`   âœ… Node created: ${fingerprint}`);

  return {
    id,
    publicKey: keypair.publicKey,
    secretKey: keypair.secretKey,
    fingerprint,
    reputation: 1.0
  };
}

/**
 * Training Node
 */
class TrainingNode {
  private identity: NodeIdentity;
  private localModel: number[][] = [];
  private trainingData: number[][] = [];
  private mlkem: MlKem768;
  private secureChannels: Map<string, Buffer> = new Map();

  constructor(identity: NodeIdentity) {
    this.identity = identity;
    this.mlkem = new MlKem768();

    // Initialize with random local model
    this.localModel = Array.from({ length: 3 }, () =>
      Array.from({ length: 10 }, () => Math.random())
    );

    // Generate synthetic training data
    this.trainingData = Array.from({ length: 100 }, () =>
      Array.from({ length: 10 }, () => Math.random())
    );
  }

  /**
   * Establish secure channel with coordinator
   */
  async connectToCoordinator(coordinatorPublicKey: Buffer): Promise<Buffer> {
    console.log(`\n[${this.identity.id}] ğŸ” Establishing secure channel with coordinator...`);

    const { ciphertext, sharedSecret } = this.mlkem.encapsulate(coordinatorPublicKey);
    this.secureChannels.set('coordinator', sharedSecret);

    console.log(`   âœ… Secure channel established`);

    return ciphertext;
  }

  /**
   * Train local model on local data
   */
  async trainLocalModel(epochs: number = 5): Promise<Gradient[]> {
    console.log(`\n[${this.identity.id}] ğŸ‹ï¸  Training local model for ${epochs} epochs...`);

    const gradients: Gradient[] = [];

    for (let epoch = 0; epoch < epochs; epoch++) {
      // Simulate training (in reality, this would be actual gradient descent)
      for (let layerIdx = 0; layerIdx < this.localModel.length; layerIdx++) {
        const gradient: number[] = this.localModel[layerIdx].map(weight => {
          // Simulate gradient calculation
          const grad = (Math.random() - 0.5) * 0.1;
          return grad;
        });

        gradients.push({
          layerId: `layer-${layerIdx}`,
          weights: gradient,
          timestamp: Date.now(),
          nodeId: this.identity.id
        });
      }

      console.log(`   Epoch ${epoch + 1}/${epochs} completed`);
    }

    console.log(`   âœ… Local training completed`);
    console.log(`   Generated ${gradients.length} gradient updates`);

    return gradients;
  }

  /**
   * Encrypt gradients for secure transmission
   */
  async encryptGradients(gradients: Gradient[]): Promise<Buffer> {
    const coordinatorSecret = this.secureChannels.get('coordinator');
    if (!coordinatorSecret) {
      throw new Error('No secure channel with coordinator');
    }

    console.log(`\n[${this.identity.id}] ğŸ”’ Encrypting gradients...`);

    const gradientsJson = JSON.stringify(gradients);
    const gradientsBuffer = Buffer.from(gradientsJson, 'utf8');

    // Simple XOR encryption for demo (in production, use proper AES-GCM)
    const encrypted = Buffer.from(gradientsBuffer).map((byte, i) =>
      byte ^ coordinatorSecret[i % coordinatorSecret.length]
    );

    console.log(`   âœ… Encrypted ${gradients.length} gradients (${encrypted.length} bytes)`);

    return encrypted;
  }

  /**
   * Receive and apply aggregated gradients
   */
  async applyAggregatedGradients(encryptedGradients: Buffer): Promise<void> {
    const coordinatorSecret = this.secureChannels.get('coordinator');
    if (!coordinatorSecret) {
      throw new Error('No secure channel with coordinator');
    }

    console.log(`\n[${this.identity.id}] ğŸ“¥ Receiving aggregated gradients...`);

    // Decrypt gradients
    const decrypted = Buffer.from(encryptedGradients).map((byte, i) =>
      byte ^ coordinatorSecret[i % coordinatorSecret.length]
    );

    const gradients: Gradient[] = JSON.parse(decrypted.toString('utf8'));

    // Apply gradients to local model
    const learningRate = 0.01;
    for (const gradient of gradients) {
      const layerIdx = parseInt(gradient.layerId.split('-')[1]);
      for (let i = 0; i < gradient.weights.length; i++) {
        this.localModel[layerIdx][i] -= learningRate * gradient.weights[i];
      }
    }

    console.log(`   âœ… Applied ${gradients.length} gradient updates`);
  }

  getIdentity(): NodeIdentity {
    return this.identity;
  }
}

/**
 * Federated Learning Coordinator
 */
class FederatedCoordinator {
  private mlkem: MlKem768;
  private identity: NodeIdentity;
  private nodes: Map<string, Buffer> = new Map();  // nodeId -> shared secret
  private currentRound: number = 0;
  private modelVersions: Map<number, string> = new Map();

  constructor(identity: NodeIdentity) {
    this.identity = identity;
    this.mlkem = new MlKem768();
  }

  /**
   * Register a training node
   */
  async registerNode(nodeIdentity: NodeIdentity, ciphertext: Buffer): Promise<void> {
    console.log(`\n[Coordinator] ğŸ“ Registering node: ${nodeIdentity.id}`);

    // Decapsulate to establish shared secret
    const sharedSecret = this.mlkem.decapsulate(ciphertext, this.identity.secretKey);
    this.nodes.set(nodeIdentity.id, sharedSecret);

    console.log(`   âœ… Node registered: ${nodeIdentity.fingerprint}`);
  }

  /**
   * Start a new training round
   */
  async startRound(): Promise<TrainingRound> {
    this.currentRound++;

    console.log(`\n${'â•'.repeat(60)}`);
    console.log(`ğŸ“Š TRAINING ROUND ${this.currentRound}`);
    console.log(`${'â•'.repeat(60)}`);

    const round: TrainingRound = {
      roundNumber: this.currentRound,
      modelVersion: blake3Hash(Buffer.from(`model-v${this.currentRound}`)).toString('hex').slice(0, 16),
      participants: Array.from(this.nodes.keys()),
      byzantineNodesDetected: []
    };

    this.modelVersions.set(this.currentRound, round.modelVersion);

    console.log(`   Model version: ${round.modelVersion}`);
    console.log(`   Participants: ${round.participants.length} nodes`);

    return round;
  }

  /**
   * Aggregate gradients from all nodes (Byzantine fault tolerant)
   */
  async aggregateGradients(encryptedGradients: Map<string, Buffer>): Promise<Gradient[]> {
    console.log(`\n[Coordinator] ğŸ”¢ Aggregating gradients from ${encryptedGradients.size} nodes...`);

    const allGradients: Map<string, Gradient[]> = new Map();

    // Decrypt gradients from each node
    for (const [nodeId, encrypted] of encryptedGradients.entries()) {
      const sharedSecret = this.nodes.get(nodeId);
      if (!sharedSecret) continue;

      // Decrypt
      const decrypted = Buffer.from(encrypted).map((byte, i) =>
        byte ^ sharedSecret[i % sharedSecret.length]
      );

      const gradients: Gradient[] = JSON.parse(decrypted.toString('utf8'));
      allGradients.set(nodeId, gradients);
    }

    // Byzantine fault tolerance: detect outliers
    const byzantineNodes = this.detectByzantineNodes(allGradients);
    console.log(`   âš ï¸  Detected ${byzantineNodes.length} Byzantine nodes`);

    // Filter out Byzantine nodes
    for (const nodeId of byzantineNodes) {
      allGradients.delete(nodeId);
    }

    // Aggregate gradients (median aggregation for Byzantine fault tolerance)
    const aggregated: Gradient[] = [];
    const numLayers = allGradients.values().next().value.length;

    for (let layerIdx = 0; layerIdx < numLayers; layerIdx++) {
      const layerGradients: number[][] = [];

      for (const nodeGradients of allGradients.values()) {
        layerGradients.push(nodeGradients[layerIdx].weights);
      }

      // Compute median for each weight (Byzantine fault tolerant)
      const aggregatedWeights = layerGradients[0].map((_, weightIdx) => {
        const values = layerGradients.map(g => g[weightIdx]).sort((a, b) => a - b);
        const mid = Math.floor(values.length / 2);
        return values.length % 2 === 0
          ? (values[mid - 1] + values[mid]) / 2
          : values[mid];
      });

      aggregated.push({
        layerId: `layer-${layerIdx}`,
        weights: aggregatedWeights,
        timestamp: Date.now(),
        nodeId: 'coordinator'
      });
    }

    console.log(`   âœ… Aggregated ${aggregated.length} layers`);

    return aggregated;
  }

  /**
   * Detect Byzantine nodes using statistical outlier detection
   */
  private detectByzantineNodes(allGradients: Map<string, Gradient[]>): string[] {
    // Simple outlier detection: if a node's gradients deviate too much from the median
    const byzantineNodes: string[] = [];

    // Calculate mean norm for each node
    const norms = new Map<string, number>();

    for (const [nodeId, gradients] of allGradients.entries()) {
      let totalNorm = 0;
      for (const gradient of gradients) {
        const norm = Math.sqrt(gradient.weights.reduce((sum, w) => sum + w * w, 0));
        totalNorm += norm;
      }
      norms.set(nodeId, totalNorm / gradients.length);
    }

    // Calculate median norm
    const normValues = Array.from(norms.values()).sort((a, b) => a - b);
    const medianNorm = normValues[Math.floor(normValues.length / 2)];

    // Flag nodes with norm > 3x median (Byzantine threshold)
    for (const [nodeId, norm] of norms.entries()) {
      if (norm > medianNorm * 3) {
        byzantineNodes.push(nodeId);
      }
    }

    return byzantineNodes;
  }

  /**
   * Broadcast aggregated gradients to all nodes
   */
  async broadcastGradients(gradients: Gradient[]): Promise<Map<string, Buffer>> {
    console.log(`\n[Coordinator] ğŸ“¡ Broadcasting aggregated gradients to all nodes...`);

    const encrypted = new Map<string, Buffer>();
    const gradientsJson = JSON.stringify(gradients);
    const gradientsBuffer = Buffer.from(gradientsJson, 'utf8');

    for (const [nodeId, sharedSecret] of this.nodes.entries()) {
      // Encrypt for each node
      const encryptedGradients = Buffer.from(gradientsBuffer).map((byte, i) =>
        byte ^ sharedSecret[i % sharedSecret.length]
      );

      encrypted.set(nodeId, encryptedGradients);
    }

    console.log(`   âœ… Broadcast to ${encrypted.size} nodes`);

    return encrypted;
  }
}

/**
 * Run a complete federated learning simulation
 */
async function runFederatedTraining() {
  console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘   Federated Learning with Quantum Security              â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  // Create coordinator
  const coordinatorIdentity = await createNodeIdentity('Coordinator');
  const coordinator = new FederatedCoordinator(coordinatorIdentity);

  // Create training nodes
  const numNodes = 5;
  const nodes: TrainingNode[] = [];

  console.log('\n--- Creating Training Nodes ---');
  for (let i = 1; i <= numNodes; i++) {
    const identity = await createNodeIdentity(`Node-${i}`);
    const node = new TrainingNode(identity);
    nodes.push(node);

    // Register with coordinator
    const ciphertext = await node.connectToCoordinator(coordinatorIdentity.publicKey);
    await coordinator.registerNode(identity, ciphertext);
  }

  // Run 3 training rounds
  const numRounds = 3;

  for (let round = 1; round <= numRounds; round++) {
    // Start round
    const roundInfo = await coordinator.startRound();

    // Each node trains locally
    console.log('\n--- Local Training ---');
    const encryptedGradients = new Map<string, Buffer>();

    for (const node of nodes) {
      const gradients = await node.trainLocalModel(5);
      const encrypted = await node.encryptGradients(gradients);
      encryptedGradients.set(node.getIdentity().id, encrypted);
    }

    // Coordinator aggregates
    const aggregatedGradients = await coordinator.aggregateGradients(encryptedGradients);

    // Broadcast to all nodes
    const broadcastGradients = await coordinator.broadcastGradients(aggregatedGradients);

    // Each node applies aggregated gradients
    console.log('\n--- Applying Aggregated Gradients ---');
    for (const node of nodes) {
      const encrypted = broadcastGradients.get(node.getIdentity().id)!;
      await node.applyAggregatedGradients(encrypted);
    }

    console.log(`\nâœ… Round ${round} completed successfully`);
  }

  console.log('\n--- Training Summary ---');
  console.log(`   Total rounds: ${numRounds}`);
  console.log(`   Participating nodes: ${numNodes}`);
  console.log(`   Security: Quantum-resistant (ML-KEM-768)`);
  console.log(`   Byzantine fault tolerance: Enabled`);
}

/**
 * Main function
 */
async function main() {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘   Prime Federated Learning with NAPI-rs                 â•‘');
  console.log('â•‘   Quantum-Resistant Distributed ML Training             â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  try {
    await runFederatedTraining();

    console.log('\n\nâœ… Federated learning example completed successfully!');
    console.log('\nKey features demonstrated:');
    console.log('  â€¢ Distributed training across multiple nodes');
    console.log('  â€¢ Quantum-resistant secure channels (ML-KEM-768)');
    console.log('  â€¢ Byzantine fault-tolerant gradient aggregation');
    console.log('  â€¢ Model versioning with BLAKE3 hashing');
    console.log('  â€¢ Privacy-preserving federated learning');

  } catch (error) {
    console.error('\nâŒ Error running federated learning example:', error);
    process.exit(1);
  }
}

// Run if executed directly
if (require.main === module) {
  main();
}

export { TrainingNode, FederatedCoordinator, createNodeIdentity, runFederatedTraining };
